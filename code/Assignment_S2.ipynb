{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*written by: Julia Knoblauch, Jana Vihs, Annika Boer, Kai Ingo Schewina*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable Recommendation Systems for Energy-Efficient Smart Home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Abstract</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final documents:\n",
    "- Assignment\n",
    "- Explainability Agent:\n",
    "- Performance Evaluation Agent:\n",
    "- requirements.txt\n",
    "- agents.py\n",
    "- helper_functions.py\n",
    "- (optional: adapt other agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dos (code mäßig):\n",
    "\n",
    "- richtiger model_type in recommendation einfügen (teilweise logit hardgecoded umstellen)\n",
    "- Wetter für usage: fehlende columns bei rec pipeline (Kai)\n",
    "- recommendation finalisieren (schöner machen, mit wetter für usage, wetter value resclane) (Julia)\n",
    "- xai eval: rf und xgb problem lösung finden (Annika, Kai)\n",
    "- code cleanen (von prints, warnings, etc.)\n",
    "\n",
    "optional:\n",
    "- images für recommendation (force_plots)\n",
    "\n",
    "Assignment:\n",
    "- expainability agent erklären in text (anstatt eigene file)\n",
    "\n",
    "# To do:\n",
    "\n",
    "- Annika und Julia: Explainability Agent: outcome explainability des activity_agents & usage agents zusammenführen für recommendation\n",
    "- Kai: Context Aware Related Literature, citation: manuell und references mit programm\n",
    "- generell Zitieren über Google Scholar: APA\n",
    "- LIME & SHAP für EBM unter model_type\n",
    "- warnings aus Outputs rausschmeißen!!! (verbose=0?)\n",
    "\n",
    "Weiteres:\n",
    "- EDA: rausschmeißen & Text ergänzen\n",
    "- formalisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents - cleaned\n",
    "1. Introduction\n",
    "2. Literature Review\n",
    "    \n",
    "    2.1 Explainable AI:\n",
    "    \n",
    "    2.2 Recommender Systems in SH\n",
    "    \n",
    "    2.3 Explainability in RS\n",
    "\n",
    "3. Methodology\n",
    "\n",
    "    3.1 Recommender System\n",
    "\n",
    "    3.2 Algorithms XAI\n",
    "        - Taxonomy: Auswahl\n",
    "        - Model-intrinsic: logit, knn, rf(?), gam\n",
    "        - Model-agnostic\n",
    "            Feature Importance: LIME, SHAP, plus evtl. CIU, DALEX, MAPLE\n",
    "    \n",
    "    3.3 Algorithms prediction:\n",
    "    adaboost, xgboost\n",
    "\n",
    "4. Experimental Design\n",
    "    \n",
    "    4.1 data organization\n",
    "    \n",
    "    4.2 Evaluation\n",
    "        - Performance\n",
    "        - Explainability\n",
    "\n",
    "5. Results\n",
    "   \n",
    "    5.1 Performance\n",
    "   \n",
    "    5.2 Explainability\n",
    "   \n",
    "    5.3 Umbenennen: Decision for model & XAI model\n",
    "   \n",
    "    5.4 Final result of RS: Recommendation + Explanation\n",
    "\n",
    "6. Discussion\n",
    "    - Contributions\n",
    "    - Limitations\n",
    "    - Implications\n",
    "    - Recommendations\n",
    "    - Future Research\n",
    "\n",
    "7. Conclusion\n",
    "\n",
    "References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. Introduction:\n",
    "    - RS & SH --> Energieeffizienz (wichtiges Problem, weil wir immer mehr Energie verbrauchen --> Quelle), Explainability Schlüssel!!! = Motivation\n",
    "        - multi-agent RS bestehend aus Agents mit folgenden Aufgaben.. (nötig für 3, nicht wegnehmen von 4)\n",
    "    - bisheriger Approach (Germain), unsere Erweiterung: Research Gap & Contribution\n",
    "    - Struktur des Notebooks\n",
    "2. Literature Review (Kai) --> Tabelle\n",
    "    - Explainable AI (XAI)\n",
    "        - Taxonomy: Annika\n",
    "        - Criteria: Julia\n",
    "    - Recommender Systems in SH: Fokus\n",
    "    - Explainability in RS: Fokus\n",
    "3. Methodology (i.e., the ML techniques that you apply)\n",
    "    - Algorithms XAI\n",
    "        - Taxonomy: Auswahl (Annika)\n",
    "        - Model-intrinsic (Annika)\n",
    "        - Model-agnostic (Machine Learning Interpretability: A Survey on Methods and Metrics)\n",
    "            - LIME (Annika)\n",
    "            - SHAP (Julia)\n",
    "            - EBM (Jana)\n",
    "        - vorgestellte Tabelle aus Präsi formaler --> Vergleich\n",
    "    - Algorithms prediction (Jana, Formel für finales Modell, mit paper)\n",
    "        xgboost, adaboost, knn, logit, rf, EBM --> warum erklärbar?\n",
    "\n",
    "4. Experimental Design (including EDA, data organization, performance measures, etc.)\n",
    "    - data organization (+ EDA von denen auf Wetterdaten + NAs Wetterdaten)\n",
    "        - agents system (Bild) (Jana)\n",
    "        - restriction to 2 households\n",
    "        - with & without weather data (Struktur, Herkunft, Nutzungsanweisung) (Kai)\n",
    "    - Evaluation\n",
    "        - Performance (Kai?)\n",
    "        - Explainability (feature importance) (Julia)\n",
    "5. Results\n",
    "    - Performance (Kai?)\n",
    "    - Explainability (Julia, Annika)\n",
    "    - Final result of RS: Recommendation + Explanation (Jana): umbennenen: Decision for model & XAI model (Julia, Annika)\n",
    "6. Discussion (Kai)\n",
    "    - ...\n",
    "    - Contributions\n",
    "    - Limitations: making usage daily\n",
    "    - Implications\n",
    "    - Recommendations\n",
    "    - Future Research: Neural Networks, mehrere recommendations pro Tag,\n",
    "\n",
    "e.g. include:\n",
    "    - no user\n",
    "    - runtime problems\n",
    "        - api weather data \n",
    "        - 4 models, 20 households\n",
    "        - Beispiel, wie lange es dauern würde, eine recommendation zu laden (aber nur 1x am Tag)\n",
    "\n",
    "7. Conclusion: zusammenfassung in 2 abschnitten\n",
    "References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Necessary packages to run notebook:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (16,5)\n",
    "\n",
    "from IPython.display import Latex\n",
    "from IPython.display import Image\n",
    "\n",
    "from helper_functions import Helper\n",
    "from agents import Performance_Evaluation_Agent\n",
    "from agents import Preparation_Agent\n",
    "from copy import deepcopy\n",
    "\n",
    "helper = Helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "\n",
    "\n",
    "Refer to MUlti Agent aus SEM IS\n",
    "\n",
    "It consists of 6 different Agents which tackle different tasks. The acutal Recommendation Agent combines the output of the Usage Agent, the Load Agent and the Activity Agent which obtain there input data from the Preparation Agent. Further Information can be found in *ref*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Literature Review\n",
    "\n",
    "To navigate the space of explanation methods, we use the taxonomy of Singh et al. (2020).\n",
    "This scheme presents one of many ways to classify different explainability methods.\n",
    "Therefore, four questions are put to the reader.\n",
    "First, it needs to be determined if the model can explain a particular model (model-specific) or many models (model-agnostic).\n",
    "Then, the models are devided into local and global models, depending on if they can explain a particular sample or the entire model.\n",
    "Additionally, the explanation can be made pre-model, in-model or post-model and last but not least, we distinguish between surrogate models, that work separately from the model and visualizations of the model.\n",
    "\n",
    "\n",
    "https://christophm.github.io/interpretable-ml-book/\n",
    "https://github.com/wangyongjie-ntu/Awesome-explainable-AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainable AI (XAI)\n",
    "**to do:**\n",
    "\"Review existing XAI approaches and examine their applicability to the RecSys@SH context\"\n",
    "\n",
    "4 Richtungen der local approaches kurz zusammenfassen:\n",
    "**Feature Importance (FI)**\n",
    "**Rule Based (RB)**\n",
    "**Prototypes (PR)**\n",
    "**Counterfactuals (CF)**\n",
    "\n",
    "-->+/- der appraoches nennen damit man in 3. erklären kann dass man FI nimmt und die Vorteile von RB\n",
    "durch den Output als Liste."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Criteria <a name=\"Criteria\"></a>\n",
    "**to do:** \"Develop your own criteria/classification for addressing the explainability issue in RecSys@SH context\"\n",
    "\n",
    "Robnik-Šikonja and Bohanec (2018) compile the following properties that differentiate the explainability models:\n",
    "- Expressive Power: What logic does the explanation follow and which language do they display?\n",
    "- Translucency: Does the model decompose the predictive model (decomposition), treat the model as black box (pedagogical), or mix these approaches?\n",
    "- Portability: Can the model be used on multiple predictive models i.e. is it model specific or agnostic?\n",
    "- Algorithmic complexity: How time-consuming are the computations?\n",
    "\n",
    "Carvalho et. al (2019) propose additional properties:\n",
    "- Stability: How stable are the explanations?\n",
    "- Data Sampling: How is the data sampled e.g. for Shapley value estimation?\n",
    "- Shuffling/Permutation: How do the algorithms shuffle the data to derive the feature importance?\n",
    "\n",
    "❗ Anders eingrenzen oder andere criterian noch vorschlagen?\n",
    "\n",
    "Note, that there is no consensus in the literature on which criteria to consult as it is very situation-dependent.\n",
    "For our context, we do not regard the portability but only evaluate LIME and SHAP that offer model-agnostic explainers.\n",
    "Translucancy is not important for that same reason since \"model-agnostic methods have zero translucency\" (Carvalho et al., 2019)\n",
    "All other criteria are used to describe and differentiate the explainability methods in section 3.\n",
    "\n",
    "Besides the explainability approaches, we also have to compare the final explanations that the models offer. To that end, Doshi-Valez & Kim (2018) classify three options to evaluate the explainability approaches.\n",
    "\n",
    "Firstly, *Application grounded Evaluation* involves using humans in the real setting i.e. we need subjects that use our recommender system in their smart home and evaluate the usefulness of the offered explanation.\n",
    "\n",
    "Secondly, *Human-grounded Metrics* would involve humans but not necessarily include the explainability\n",
    "approach in a real task. In our case, we could do experiments in which subjects have to choose between the explainability approach e.g. based on their preference.\n",
    "\n",
    "Thirdly, Doshi-Valez and Kim (2018) propose *Functionally-grounded Evaluation* that use proxies to evaluate the\n",
    "explainability approach.\n",
    "We use the third approach as evaluations that involve the actual application of the recommender system are out of scope for this seminar and the evaluation with humans and simplified tasks might not offer much external validity to the real setting. The specific proxies that we use for evaluating the individual explanations are described in chapter 4."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender Systems in SH: Fokus\n",
    "Recommender Systems tackle the energy efficiency problem through behavioral change [Einleitung?]. Have been applied a lot to other areas such as health, e-commerce, movies, but not that much to smart homes. Himeur et al. (2021) recently reviewed the existing approaches and deliver an exhaustive taxonomy, of which we will shortly present two aspects to classify our own system in the space of possibilities.\n",
    "\n",
    "Regarding the objective of the recommender system, there exist two types, namely strategy recommenders, and action recommenders (Himeur et al. 2021). While the first type deals with long-term questions, such as the prediction of energy consumption in a building, the second tries to recommend actions to the occupants in order to optimize their behavior. Therefore, we apply an action recommender.\n",
    "\n",
    "Secondly, there exist a multitude of methodologies and algorithms to achieve the task of energy efficiency by providing recommendations to users. The different options are displayed in Table X.\n",
    "\n",
    "|     Methodology                                |     Description                                                                                                                   |     Example    |\n",
    "|------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|----------------|\n",
    "|     Case-based                                 |     Rule-based usage habits recommended to end-users                                                                              |                |\n",
    "|     Collaborative filtering                    |     Closed set of actions, identify the preferred action                                                                          |                |\n",
    "|     Context-aware                              |     Recommendations adjusted to circumstances of end-user, historical data as basis                                               |                |\n",
    "|     Rasch-based                                |     Rasch analysis explores probability that end-user follows recommendation                                                      |                |\n",
    "|     Probabilistic relational models   (PRM)    |     Captures users and transactions in a relational database and derives tailored recommendations                                 |                |\n",
    "|     Fusion-based                               |     Different kinds of data help producing better predictions of habits, either by aggregating data or using   subrecommenders    |                |\n",
    "|     Deep learning-based                        |     Utilize the ability of deep learning to detect patterns in the data                                                           |                |\n",
    "|     Classical optimization                     |     Calculate optimal energy usage and provide insight to end-users and producers                                                 |                |\n",
    "\n",
    "Our approach is part of the fusion-based recommender systems due to our inclusion of multiple data sources (i.e. historical user behavior, weather and energy price data). There is no article identified by Himeur et al. (2021) that combines this objective and methodology, and we therefore identify and address a research gap in this area. Jimenez-Bravo et al. (2019) applied a fusion-based approach to the energy efficiency problem in smart homes by combining electricity prices and household data. Their agent structure allows for similar behavior than our recommender system and therefore serves as an inspiration to our setup. Also, we both try to achieve our goal by suggesting to shift usages to more optimal timings. Contrarily, they address the strategy objective and do not allow for further data inclusion such as weather data.\n",
    "\n",
    "Furthermore, we exhibit characteristics of the context-aware approach, as we include circumstances such as the availability of the user while calculating our recommendations.\n",
    "\n",
    "Hier ergänzen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explainability in RS: Fokus\n",
    "Himeur et al. (2021) provide an overview of current research gaps in the energy efficiency in smart home research area, in addition to their review of the state-of-the-art. We address one of the research gaps, i.e the explainability issue in recommender systems.\n",
    "\n",
    "While Zhang & Chen (2018) provide an exhaustive review of the current literature on explainability in recommender systems, they do not limit themselves by the application environment (i.e. smart homes). Their classification scheme includes the form of explanation (e.g. textual, visual, hybrid …) and the explainable recommendation model (e.g. topic modeling, matrix factorization, post-hoc, …).\n",
    "\n",
    "We utilize textual, post-hoc explanations, while simultaneously addressing the research gap identified by Zhang & Chen (2018) with regards to further aspects of explanation beyond persuasiveness (i.e. trustworthiness). Early research on trustworthiness is conducted by Cramer et al. (2008), that apply a system for artwork recommendations. Their results suggest a positive influence of explainability on the acceptance of the suggestions, while displaying the certainty of the system did not yield positive effects.\n",
    "\n",
    "Sardianos et al. (2020) apply a context-aware recommendation system in a smart home ecosystem, that additionally delivers economical or ecological advantages, as well as explanations on the decision-making process. By conducting an experimental process, they conclude that only displaying the persuasive fact is not sufficient to achieve significant behavioral change. Contrarily, displaying the advantages, as well as the reasoning behind it, leads to a 19% increase in acceptance ratio.\n",
    "\n",
    "Overall, there is very few work on explainability in recommender systems in the smart home ecosystem. We address current issues in this research area to increase trustworthiness and therefore behavioral change with regard to economical and ecological improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 XAI Alogorithms\n",
    "### (Taxonomy Auswahl?)\n",
    "\n",
    "In this paper we will deal with both kinds of explainability methods, the model-intrinsic and the model-agnostic ones.\n",
    "We will use the three model-intrinsic approaches logit, explainable boosting machines and random forest.\n",
    "These models are already inherently interpretable.\n",
    "Additionally, we use the model-agnostic approaches LIME and SHAP that are able to explain the prediction of any classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-Intrinsic Approaches\n",
    "\n",
    "The lack of transparency and accountability in high stakes-decision making using black-box models can have severe consequences.\n",
    "That led researchers concentrate on model-intrinsic explainability approaches which means that they are inherently explainable.\n",
    "\n",
    "\n",
    "paper:\n",
    "https://arxiv.org/pdf/1811.10154.pdf\n",
    "https://arxiv.org/abs/2006.06466\n",
    "\n",
    "Logit as benchmark?, GAMMLI, Random Forest (?)\n",
    "### Model-Agnostic Approaches\n",
    "\n",
    "Because of the wide use of black-box models in machine learning the need for model-agnostic approaches is immense.\n",
    "The here used approaches LIME and SHAP are feature attribution methods.\n",
    "This means they elaborate on which features are most influential in the black-box model's prediction.\n",
    "These models do not have direct access to the internal model weights or structural parameters of the black-box model."
   ]
  },
  {
   "attachments": {
    "LIME_Image_Intuition.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME\n",
    "\n",
    "One model-agnostic approach is LIME, developed by Ribeiro et al. (2016). LIME stands for \"local, interpretable, model-agnostic explanation\" and focuses on explaining the prediction of a single instance of data in an interpretable and faithful manner.\n",
    "Explaining here means that it is made transparent to the user which characteristics have most influence in the black-box model's prediction.\n",
    "The predictions produced by LIME are obtained by the minimization problem\n",
    "$$\\xi(x) = \\underset{g~\\in~G}{\\operatorname{argmin}} \\mathcal{L} (f, g, \\pi_x) - \\Omega (x) $$\n",
    "\n",
    "where the input data point $x$ is one single instance with properties like the hour, a high temperature or the day name \"Wednesday\".\n",
    "The optimization problem gets fed with the complex model $f$, that LIME tries to explain, and the simple model $g$ that comes from a family of interpretable models $G$, like e.g., linear regression.\n",
    "The first loss term embodies the fidelity of the simple model approximating the complex model in the neighborhood of $x$.\n",
    "In order to learn the local behavior of the complex model, the fidelity function \\mathcal{L} is approximated by drawing samples, weighted by $\\pi(x)$, that behaves like a proximity measure of the sampled data points to $x$.\n",
    "The second loss term $\\Omega(x)$ is used to regularize the complexity of the simple model $g$ like we know from LASSO or RIDGE regression for the linear model.\n",
    "\n",
    "The following figure shall help for a better intuition of LIME. \n",
    "![LIME_Image_Intuition.jpg](attachment:LIME_Image_Intuition.jpg)\n",
    "The blue and pink background shows the black-box model’s decision function $f$, that is unknown and nonlinear. Thus, it can not be well approximated by a linear model. The aim is to explain the bold red cross, a single instance's prediction of the black-box model. The LIME Algorithm then samples instances around the red cross by changing the feature values just a little bit. It then gets predictions using the complex model $f$.\tThe sampled instances then are weighted by the proximity to the bold red cross and the dashed line shows the learned explanation, that is locally faithful (but not globally).\n",
    "\n",
    "The plot below shows the output of the LIME function. \n",
    "\n",
    "PLOT OF LIME FUNCTION HERE\n",
    "\n",
    "It is a list of local explanations, reflecting the contribution of the features to the individual prediction of the black-box model. The output shown here is about the activity agent that predicts if a person is available to use a device at e.g., 9 o’clock on Monday. The predicted value is one, so the person is predicted to be at home and in this graph you can see which features have the most impact on the prediction. The orange bars show features pushing the prediction into the positive direction and the blue bars are pushing it in the negative direction. The hour 9 for example has positive influence but the day name \"Wednesday\" has negative influence. Overall the orange bars weight more and so the prediction is 1. \n",
    "\n",
    "Characteristics of LIME: \n",
    "LIME can handle tabular, text and image data.\n",
    "\n",
    "\n",
    "\n",
    "xgboost: resources to implement\n",
    "https://github.com/marcotcr/lime/issues/334\n",
    "https://github.com/adriamoya/xgboost_default_companies/blob/master/main.py\n",
    "mention current approaches (no implementation as far as I know except SP-LIME for global)\n",
    "https://arxiv.org/abs/2106.07875\n",
    "\n",
    "Benchmarking and Survey of Explanation Methods for\n",
    "Black Box Models - see chapter 4.1 for variants of LIME\n",
    "\n",
    "https://arxiv.org/abs/2012.00093"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP (SHapley Additive exPlanations)\n",
    "*Work in progress*\n",
    "\n",
    "SHAP uses the concept of Shapley Values (SV) from Game Theory to explain the prediction of a black-box model by computing the contribution of each feature to the prediction.\n",
    "\"An intuitive way to understand the Shapley value is the following illustration: The feature values enter a room in random order. All feature values in the room participate in the game (= contribute to the prediction). The Shapley value of a feature value is the average change in the prediction that the coalition already in the room receives when the feature value joins them.\" (Molnar, 2021)\n",
    "\n",
    "Lundberg & Lee (2017) provide an estimation of SV via additive feature attributions methods similar to the addative function found in LIME.\n",
    "They show that under specific settings the additive model estimates SV which means that the results meets the theoretical properties of local accuracy, missingness and consistency (Lundberg & Lee, 2017).\n",
    "\n",
    "*❗ umschreiben (?) und estimation und notation aus LIME nutzen (?) ❗*\n",
    "\n",
    "In our work we will use two types of explainers provided in the package.\n",
    "\n",
    "**KernelExplainer**\n",
    "This explainer introduced in Lundberg & Lee (2017) is model agnostic and gets its name from the shapley kernel $ \\pi_{x'} $ which is no longer computed heuristically as in LIME.\n",
    "\n",
    "The alogritm first samples if the features are present in the coalition $z_{k}^{\\prime} \\in\\{0,1\\}^{M}, \\quad k \\in\\{1, \\ldots, K\\}$. We then get the prediction for the coalitions with a mapping function $h_x$ which retrieves the original feature values. If the feature is not present in the coalition the feature value is replaced by a random feature from the sample i.e we sample from the marginal distribution. The coalitions are each weighted with the SHAP kernal (Molnar, 2021).\n",
    "\n",
    "\n",
    "The kernel is predetermined where $M$ represent the number of input features, $|z'|$ is the number of present feature in instance $z'$ and $x$ is the local instance we want to explain (Molnar, 2021):\n",
    "\n",
    "$$\n",
    "\\pi_{x^{\\prime}}\\left(z^{\\prime}\\right)=\\frac{(M-1)}{\\left(M \\text { choose }\\left|z^{\\prime}\\right|\\right)\\left|z^{\\prime}\\right|\\left(M-\\left|z^{\\prime}\\right|\\right)}\n",
    "$$\n",
    "\n",
    "The linear model $g\\left(z^{\\prime}\\right)$ is then just:\n",
    "$$g\\left(z^{\\prime}\\right)=\\phi_{0}+\\sum_{j=1}^{M} \\phi_{j} z_{j}^{\\prime}$$\n",
    "\n",
    "where $\\phi_{j}$ are the SV we want to estimate.\n",
    "\n",
    "Furthermore, the regularization term $\\Omega(g)$ is set to 0 which results in the following kernel-weighted squared loss funtion to be minimized (Lundberg & Lee, 2017).\n",
    "\n",
    "$$\n",
    "L\\left(f, g, \\pi_{x^{\\prime}}\\right)=\\sum_{z^{\\prime} \\in Z}\\left[f\\left(h_{x}\\left(z^{\\prime}\\right)\\right)-g\\left(z^{\\prime}\\right)\\right]^{2} \\pi_{x^{\\prime}}\\left(z^{\\prime}\\right)\n",
    "$$\n",
    "\n",
    "The estimated values can then be interpreted as SV.\n",
    "A drawback from sampling from the marginal distribution is that we ignore dependencies between features (Molnar, 2021).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TreeExplainer** This explainer is model-specific to trees. We have decided to include it nevertheless since 2 of the 5 evaluated models are tree-based and the calculation is  more efficicient.\n",
    "\n",
    "Note, that the theoretical underpinnings are not quite the same as the sampling differs (Lundberg et al., 2020).\n",
    "\n",
    "*hier weiter arbeiten!*\n",
    "we use Interventional Feature Perturbation (aka use background dataset) to make it more close to model agnostic version\n",
    "\n",
    "https://github.com/SeldonIO/alibi/blob/c495f9b02f8b6ca5d6d0046f0fe1e466bf8af336/examples/interventional_tree_shap_adult_xgb.ipynb\n",
    "https://docs.seldon.io/projects/alibi/en/stable/examples/interventional_tree_shap_adult_xgb.html\n",
    "\n",
    "Instead of the marginal expectation, TreeSHAP uses the conditional expectations $E_{X_{S} \\mid X_{C}}\\left(f(x) \\mid x_{S}\\right)$ to sample absent features (?).\n",
    "\n",
    "This becomes a problem if features are correlated as now the estimated SV might not be zero but indicate a contribution where there is none. This is a disadvantage compared to KernelSHAP which potentially creates unintuitive feature attributions if features are correlated (Molnar, 2021).\n",
    "\n",
    "We use the KernelExplainer for explaining logit, ada and knn. We summarize the data before with the k-means clustering (k=10) for a faster estimation.\n",
    "We use the TreeExplainer for random forest and xgboost nevertheless since the computation time is an issue we face.\n",
    "\n",
    "❗ *add to discussion of results* ❗"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Beispiel mit activity agent?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Explanation:\n",
    "\n",
    "Output value: final prediction by surrogate model for instance\n",
    "\n",
    "Base value: mean prediction for dataset\n",
    "\n",
    "Red/Blue arrows: represent shapley values (push prediction from base value to higher (red) or lower (blue) level)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As mentioned, SHAP builds on the fair distribution of feature importance scores and uses the plots from above to convey their solution to the user. However, the interpretation is not as easy to the untrained eye. The computation of SV in general is quite computationnally intensive. SHAP remedies some of that problem through their estimation but KernelSHAP is nevertheless quite slow. This is especially a problem for global calculations (Molnar, 2021). Since the time needed for the calculation of explainations is so essential to the production environment we measure the time needed to create a local explanation in our evaluation.\n",
    "\n",
    "❗ Was ist mit stability of SHAP?\n",
    "\n",
    "When it comes to the criterion permutation, both LIME and KernelSHAP have the same shortcomings as other permutation-based appraoches as they just use random data points to sample. TreeSHAP partly remedies that problem by sampling from the conditional distribution which however creates other problems i.e. \"features that have no influence on the prediction can get a TreeSHAP value different from zero\" (Molnar, 2021).\n",
    "\n",
    "*idee: eventuell noch untersuchen wie relations sind zwischen featues um probleme auszuschließen?*\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't put in eval but maybe mention (?)\n",
    "**MUSE**\n",
    "chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Fcs.stanford.edu%2Fpeople%2Fjure%2Fpubs%2Fexplanations-aies19.pdf&clen=1929781&chunk=true\n",
    "\"Faithful and Customizable Explanations of Black Box Models\"\n",
    "--> give concrete measures for xai other than fidelity\n",
    "but: not open source package?\n",
    "\n",
    "slides:\n",
    "chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https%3A%2F%2Finterpretable-ml-class.github.io%2Fslides%2FLecture_11.pdf&clen=1064587&chunk=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't put in eval but maybe mention:\n",
    "**BETA**\n",
    "https://arxiv.org/pdf/1707.01154.pdf\n",
    "Interpretable & Explorable Approximations of Black Box Models\n",
    "--> global approach, no package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from paper Bodria et. a. (2021):\n",
    "see table 1 for overview on what else we could look at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't put in eval but maybe mention:\n",
    "**py-ciu**\n",
    "https://arxiv.org/abs/2006.00199\n",
    "Explanations of Black-Box Model Predictionsby Contextual Importance and Utility\n",
    "https://github.com/TimKam/py-ciu\n",
    "--> also nice because working textual output\n",
    "--> aber: kein prediction model daraus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAPLE**\n",
    "-> check if they do surrogate model/ we would need to add to eval\n",
    "https://github.com/GDPlumb/MAPLE\n",
    "https://arxiv.org/abs/1807.02910\n",
    "aber keine ahnung wie output ist & schlechte documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3 Prediction Algorithms\n",
    "\n",
    "\n",
    "The following classical prediction algorihms were used:\n",
    "\n",
    "**K-Nearest-Neighbour**: A classification algorithm (Cunningham et. al. 2020), where examples are classified based on the class of thir nearest neighbours.\n",
    "\n",
    "**Logistic Regression**: A statistical model which usually refers to regression analyses for modeling the probability  of a certain class or event which in a binary problem which easily can be extended to model a multinomial class problem (Peng et. al. 2002).\n",
    "\n",
    "**Random Forest**: A combination of tree predictors, where each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest (Breiman, 2001).\n",
    "\n",
    "**XGBoost** : A scalable end-to-end tree boosting system , which is used widley by data scientists to achieve state-of-the-art results (Chen et. al. 2016).\n",
    "\n",
    "**AdaBoost**: A boosting algorithm which was first introduced by Freund and Schapire (1995), where one of the main ideas is to maintain a distribution or a set of weigths over the training set.\n",
    "\n",
    "To include a global explainability approach we decided to include the following model.\n",
    "\n",
    "**Explainable Boosting Maschine**: A glassbox model, which is a generalized additive model (GAM) of the form \n",
    "$$g(E[y]) = \\beta_{0} + \\sum f_{j}(x_{j}),$$ where $g$ denotes the link function which adapts the GAM to different application settings like classification or regression (H. Nori et. al. 2019). It is being highly intelligibile and explainable while being designed to have accuracy comparable to state-of-the-art machine learning models like Random Forest and Boostes Trees. Further, it is an additive model, which means that each feature contributes to predictions in a modular way. Hence, it is easy to reason about the contribution of each feature to the prediciton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Experimental Design \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following picture represents the Multi Agent with our modifications.\n",
    "We developed an Explainability Agent, which... TO BE CONTINUED\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='../pictures/structure.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data\n",
    "\n",
    "The underlying data consist out of the REFIT Data which are Electrical Load Measurements provided by Murray et al. (2017). The data contains the energy consumption of nine different devices in Watts used in 20 households in the United Kingdom as well as the aggregate energy consumption in each household over the period 2013 to 2015. As the data only contains these energy consumption measured at eight-second intervals, we need to perform a few preparation steps including aggregating the data, cleaning the data, creating our target features and further feature creation. This task is tackled by the Prepapration Agent.\n",
    "In order to improve our current Multi-Agent we extended our data set with specific weather features using the API from meteostat https://github.com/meteostat/meteostat-python.\n",
    "The weather might be of cruical importance for the usage of some devices in a household. Hence we scraped the following additional features:\n",
    "\n",
    "*dwpt* : The dew point in °C \n",
    "\n",
    "*rhum*: The relative humidity in perecent (%)\n",
    "\n",
    "*temp* : The air temperature in °C\n",
    "\n",
    "*wdir* : The average wind direction in degrees (°)\n",
    "\n",
    "*wspd* : The avaerge wind speed in km/h\n",
    "\n",
    "For some data points there existed missing values which where imputed by using teh K-Nearest-Neighbour Algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explorative Data Analysis\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation of data \n",
    "truncation_params = {\n",
    "    'features': 'all', \n",
    "    'factor': 1.5, \n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "scale_params = {\n",
    "    'features': 'all', \n",
    "    'kind': 'MinMax', \n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "aggregate_params = {\n",
    "    'resample_param': '60T'\n",
    "}\n",
    "\n",
    "shiftable_devices = ['Tumble Dryer', 'Washing Machine', 'Dishwasher'] # computer und tv sind m. E. non-shiftable, VR\n",
    "\n",
    "device_params = {\n",
    "    'threshold': 0.15\n",
    "}\n",
    "\n",
    "load_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'aggregate': aggregate_params,\n",
    "    'shiftable_devices': shiftable_devices, \n",
    "    'device': device_params\n",
    "}\n",
    "\n",
    "# Load household and preprocess\n",
    "household_id = 3\n",
    "household = helper.load_household(DATA_PATH, household_id, weather_sel=True)\n",
    "output, scaled, df = Preparation_Agent(household).pipeline_load(household, load_pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following correlation plot displays a positive correlation between the usage of the washing machine and the tumble dryer, which was expected, as if you use the washing machine and own a tumble dryer one would usually use it afterwards. Furthermore there seem to be strong positive correlation between the relative humidity (rhum) and the dew point (dwpt) and a strong negative correlation between the air temeprature (temp) and the dew point (dwpt).\n",
    "n general, it can be said that the data are positively correlated with each other, but there are no strong interdependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Correlation of weather features and Usage of Devices')\n",
    "weather_df = df[['Tumble Dryer_usage', 'Washing Machine_usage', 'Dishwasher_usage','dwpt', 'rhum', 'temp', 'wdir', 'wspd']]\n",
    "sns.heatmap(weather_df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to examine if a device was used multiple times each day. As for the tumble dryer there exist dates were it was used 8 times, the washing machine was used 9 times a day and the dishwasher was used 7 times a day as a max, which is rather rare but interesting for our recommendation system when it comes to saving energy and money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tumble Dryer in use\n",
    "reIndexed = df.reset_index()\n",
    "reIndexed['Date'], reIndexed['clock'] = reIndexed['Time'].apply(lambda x: x.date()), reIndexed['Time'].apply(lambda x: x.time())\n",
    "wm = reIndexed['Washing Machine_usage']==1\n",
    "td = reIndexed['Tumble Dryer_usage']==1\n",
    "dw = reIndexed['Dishwasher_usage'] ==1\n",
    "td_inuse = reIndexed[td]\n",
    "td_inuse.groupby('Date')[['Tumble Dryer_usage']].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Washing Machine in use\n",
    "wm_inuse = reIndexed[wm]\n",
    "wm_inuse.groupby('Date')[['Washing Machine_usage']].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dishwasher in use \n",
    "dw_inuse = reIndexed[dw]\n",
    "dw_inuse.groupby('Date')[['Dishwasher_usage']].count().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All devices show a mean around two, so on average each device is used two times a day.\n",
    "As expected the following distplot shows a similiar distribution of the usage of the washing machine and the tumble dryer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Distribution of Tumble Dryer and Washing Machine Usage')\n",
    "sns.distplot(td_inuse['Date'].value_counts().values)\n",
    "sns.distplot(wm_inuse['Date'].value_counts().values)\n",
    "plt.legend(labels=['Tumble Dryer', 'Washing Mashine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Distribution of Dishwasher Usage')\n",
    "sns.distplot(dw_inuse['Date'].value_counts().values, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at dates of interest for Tumble dryer and Washing Machine\n",
    "df_20_04_2014 = df[['dwpt','rhum','temp','wdir','wspd','Tumble Dryer_usage', 'Washing Machine_usage']].filter(like='2014-04-20', axis=0)\n",
    "df_10_08_2014 = df[['dwpt','rhum','temp','wdir','wspd','Tumble Dryer_usage', 'Washing Machine_usage']].filter(like='2014-08-10', axis=0)\n",
    "df_03_09_2015 = df[['dwpt','rhum','temp','wdir','wspd','Tumble Dryer_usage', 'Washing Machine_usage']].filter(like='2015-09-03', axis=0)\n",
    "df_26_06_2014 = df[['dwpt','rhum','temp','wdir','wspd','Tumble Dryer_usage', 'Washing Machine_usage']].filter(like='2014-06-26', axis=0)\n",
    "df_28_09_2013 = df[['dwpt','rhum','temp','wdir','wspd', 'Tumble Dryer_usage', 'Washing Machine_usage']].filter(like='2013-09-28', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at dates of interest for Dishwasher\n",
    "df_27_09_2013 = df[['dwpt','rhum','temp','wdir','wspd','Dishwasher_usage']].filter(like='2013-09-27', axis=0)\n",
    "df_25_11_2014 = df[['dwpt','rhum','temp','wdir','wspd' ,'Dishwasher_usage']].filter(like='2014-11-25', axis=0)\n",
    "df_19_10_2014 = df[['dwpt','rhum','temp','wdir','wspd', 'Dishwasher_usage']].filter(like='2014-10-19', axis=0)\n",
    "df_01_07_2014 = df[['dwpt','rhum','temp','wdir','wspd', 'Dishwasher_usage']].filter(like='2014-07-01', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will examine the courses of the weather features and the use of the different household devices in order to detect any relations between those properties.\n",
    "Especially those dates were each device is used multiple times are of great interest.\n",
    "When it comes to the usage of the washing machine and tumble dryer, the course of the graphs confirms once again that the dryer is mostly used after the washing machine. Almost everytime those devices are used there seem to be a drop in the weather features, which indicates that those features would be helpful for our recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Plot\n",
    "def plot_df(df, x, y, title=\"\", xlabel='TIme', ylabel='Value', dpi=100, axvspan=True):\n",
    "    plt.figure(figsize=(16,5), dpi=dpi)\n",
    "    plt.plot(x, y, marker='o')\n",
    "    plt.legend(df_27_09_2013.columns.tolist())\n",
    "   \n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plot_df(df_27_09_2013, x=df_27_09_2013.index, y=df_27_09_2013.values, title='Tumble Dryer and Waching Machine Usage on the 27.09.2013')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the days were each device was used multiple times like the 28.09.2013 or the 10.08.2014 were the tumble dryer was used 8 times a day it is important to note that it seemed to be running for 8 hours. In order to get a more precise insight into the user behavior at such special events, it would be useful to enrich our data with exact start and end times for each dryer cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df_28_09_2013, x=df_28_09_2013.index, y=df_28_09_2013.values, title='Tumble Dryer and Washing Machine Usage on the 28.09.2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df_10_08_2014, x=df_10_08_2014.index, y=df_10_08_2014.values, title='Tumble Dryer and Washing Machine Usage on the 10.08.2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df_26_06_2014, x=df_26_06_2014.index, y=df_26_06_2014.values, title='Tumble Dryer and Washing Machine Usage on the 26.06.2014')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to the course of dishwasher use and weather data, no strong correlations can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df_25_11_2014, x=df_25_11_2014.index, y=df_25_11_2014.values, title='Dishwasher Usage on the 25.11.2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df_19_10_2014, x=df_19_10_2014.index, y=df_19_10_2014.values, title='Dishwasher Usage on the 19.10.2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(df_01_07_2014, x=df_01_07_2014.index, y=df_01_07_2014.values, title='Dishwasher Usage on the 01.07.2014')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the relationship between the weather features and the usage of the devices of a household are worth investigating and will be further pursued when it comes to improving our Multi-Agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance (Kai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explainability (Julia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When it comes to our evaluation of the explainability approaches we want to quantitatively compare the\n",
    "individual explanations that the models offer. The literature does not propose one clear framework which metrics to use as it is also highly application dependent.\n",
    "Nevertheless, we will use the following concepts that are widely applied to determine how well\n",
    " the explainability approaches work in giving accurate local explanations (Carvalho et. al, 2019):\n",
    "\n",
    "**Accuracy** Similar to predictive accuracy, the accuracy of the explanation method refers to how well the explainable model\n",
    "predicts unseen instances compared to the real outcome. We will also use the Are Under the ROC-Curve (AUC) as a measure to compare the true labels with the predictions from the explainers.\n",
    "\n",
    "**Fidelity** This criterion determines how close the prediction from the explainable model is to the black-box model's prediction.\n",
    "Therefore, fidelity describes how well the explainability model can imitate the prediction of the black-box model.\n",
    "We use the measure AUC again but replace the target label with the predictions from the black-box model.\n",
    "Note that Carvalho et. al (2019) mention an interrelation between these two concepts: black-box models with high predictive\n",
    "accuracy and explanations that offer a high fidelity are also highly accurate when it comes to real predictions. This is\n",
    "the ideal that we would like to achieve.\n",
    "\n",
    "Additionally, we calculate the *Mean-Squared-Explainability Error* (MSEE) for every approach to measure not only if\n",
    "the decision of the black-box model and the explainability approach is the same but also to measure how close they are to each other.\n",
    "This metric represents how well the explainability approaches are calibrated. The formula of the traditionally used\n",
    "Mean-Squared-Error is adapted in the following way: (citation? kann gerade iwie keine finden...)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$ MSEE_{} = \\frac{1}{n} (y_{pred} - y_{expl})^2 $$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Efficiency (Algorithmic complexity)** Lastly, we evaluate how efficient the explainability approaches are in calculating\n",
    "the local explanations. To the end, we measure the time that each method needs to calculate all the\n",
    "local explanations for a day and average the values for all calculations (Carvalho et. al, 2019).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Idee: ROC Curve with Accuracy and Fidelity\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umbenennen: Decision for model & XAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# loading necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from helper_functions import Helper\n",
    "from agents import Preparation_Agent\n",
    "from datetime import datetime\n",
    "\n",
    "helper = Helper()\n",
    "\n",
    "DATA_PATH = '../data/'\n",
    "\n",
    "# load household data for Household 3\n",
    "household = helper.load_household(DATA_PATH, 3, weather_sel=True)\n",
    "\n",
    "threshold = 0.01\n",
    "active_appliances = ['Toaster', 'Tumble Dryer', 'Dishwasher', 'Washing Machine','Television', 'Microwave', 'Kettle']\n",
    "shiftable_devices = ['Tumble Dryer', 'Washing Machine', 'Dishwasher']\n",
    "\n",
    "#activity params\n",
    "truncation_params = {\n",
    "    'features': 'all',\n",
    "    'factor': 1.5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "scale_params = {\n",
    "    'features': 'all',\n",
    "    'kind': 'MinMax',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "aggregate_params = {\n",
    "    'resample_param': '60T'\n",
    "}\n",
    "\n",
    "activity_params = {\n",
    "    'active_appliances': active_appliances,\n",
    "    'threshold': threshold\n",
    "}\n",
    "\n",
    "time_params = {\n",
    "    'features': ['hour', 'day_name']\n",
    "}\n",
    "\n",
    "activity_lag_params = {\n",
    "    'features': ['activity'],\n",
    "    'lags': [24, 48, 72]\n",
    "}\n",
    "\n",
    "activity_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'aggregate': aggregate_params,\n",
    "    'activity': activity_params,\n",
    "    'time': time_params,\n",
    "    'activity_lag': activity_lag_params\n",
    "}\n",
    "\n",
    "#load agent\n",
    "device_params = {\n",
    "    'threshold': threshold\n",
    "}\n",
    "\n",
    "load_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'aggregate': aggregate_params,\n",
    "    'shiftable_devices': shiftable_devices,\n",
    "    'device': device_params\n",
    "}\n",
    "\n",
    "#usage agent\n",
    "\n",
    "device = {\n",
    "    'threshold' : threshold}\n",
    "\n",
    "aggregate_params24_H = {\n",
    "    'resample_param': '24H'\n",
    "}\n",
    "\n",
    "usage_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'activity': activity_params,\n",
    "    'aggregate_hour': aggregate_params,\n",
    "    'aggregate_day': aggregate_params24_H,\n",
    "    'time': time_params,\n",
    "    'activity_lag': activity_lag_params,\n",
    "    'shiftable_devices' : shiftable_devices,\n",
    "    'device': device\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# calling the preparation pipeline\n",
    "#prep = Preparation_Agent(household)\n",
    "#activity_df = prep.pipeline_activity(household, activity_pipe_params)\n",
    "#load_df, _, _ = prep.pipeline_load(household, load_pipe_params)\n",
    "#usage_df = prep.pipeline_usage(household, usage_pipe_params)\n",
    "\n",
    "# load price data\n",
    "# FILE_PATH = '/content/drive/MyDrive/T4_Recommendation-system-for-demand-response-and-load-shifting/02_data/'\n",
    "#price_df = helper.create_day_ahead_prices_df(DATA_PATH, 'Day-ahead Prices_201501010000-201601010000.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#activity_df.to_pickle('../data/processed_pickle/activity_df.pkl')\n",
    "#load_df,_, _ .to_pickle('../data/processed_pickle/load_df.pkl')\n",
    "#usage_df.to_pickle('../data/processed_pickle/usage_df.pkl')\n",
    "#price_df.to_pickle('../data/processed_pickle/price_df.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load pickle data\n",
    "activity_df = pd.read_pickle('../data/processed_pickle/activity_df.pkl')\n",
    "load_df = pd.read_pickle('../data/processed_pickle/load_df.pkl')\n",
    "usage_df = pd.read_pickle('../data/processed_pickle/usage_df.pkl')\n",
    "price_df = pd.read_pickle('../data/processed_pickle/price_df.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from exp_agents import Activity_Agent, Usage_Agent, Load_Agent, Price_Agent, X_Recommendation_Agent, Explainability_Agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "recommend = X_Recommendation_Agent(activity_df, usage_df, load_df, price_df, shiftable_devices, model_type='random forest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                     Price_at_H+0  Price_at_H+1  Price_at_H+2  Price_at_H+3  \\\nTime                                                                          \n2014-08-21 00:00:00         32.51         32.36         31.94         31.00   \n2014-08-21 01:00:00         32.36         31.94         31.00         33.90   \n2014-08-21 02:00:00         31.94         31.00         33.90         38.01   \n2014-08-21 03:00:00         31.00         33.90         38.01         38.71   \n2014-08-21 04:00:00         33.90         38.01         38.71         39.51   \n2014-08-21 05:00:00         38.01         38.71         39.51         49.53   \n2014-08-21 06:00:00         38.71         39.51         49.53         48.47   \n2014-08-21 07:00:00         39.51         49.53         48.47         48.47   \n2014-08-21 08:00:00         49.53         48.47         48.47         43.21   \n2014-08-21 09:00:00         48.47         48.47         43.21         36.01   \n2014-08-21 10:00:00         48.47         43.21         36.01         35.09   \n2014-08-21 11:00:00         43.21         36.01         35.09         35.45   \n2014-08-21 12:00:00         36.01         35.09         35.45         38.89   \n2014-08-21 13:00:00         35.09         35.45         38.89         48.03   \n2014-08-21 14:00:00         35.45         38.89         48.03         47.05   \n2014-08-21 15:00:00         38.89         48.03         47.05         42.15   \n2014-08-21 16:00:00         48.03         47.05         42.15         43.34   \n2014-08-21 17:00:00         47.05         42.15         43.34         39.73   \n2014-08-21 18:00:00         42.15         43.34         39.73         39.03   \n2014-08-21 19:00:00         43.34         39.73         39.03         38.04   \n2014-08-21 20:00:00         39.73         39.03         38.04         36.47   \n2014-08-21 21:00:00         39.03         38.04         36.47         35.12   \n2014-08-21 22:00:00         38.04         36.47         35.12         33.97   \n2014-08-21 23:00:00         36.47         35.12         33.97         33.52   \n\n                     Price_at_H+4  Price_at_H+5  Price_at_H+6  Price_at_H+7  \\\nTime                                                                          \n2014-08-21 00:00:00         33.90         38.01         38.71         39.51   \n2014-08-21 01:00:00         38.01         38.71         39.51         49.53   \n2014-08-21 02:00:00         38.71         39.51         49.53         48.47   \n2014-08-21 03:00:00         39.51         49.53         48.47         48.47   \n2014-08-21 04:00:00         49.53         48.47         48.47         43.21   \n2014-08-21 05:00:00         48.47         48.47         43.21         36.01   \n2014-08-21 06:00:00         48.47         43.21         36.01         35.09   \n2014-08-21 07:00:00         43.21         36.01         35.09         35.45   \n2014-08-21 08:00:00         36.01         35.09         35.45         38.89   \n2014-08-21 09:00:00         35.09         35.45         38.89         48.03   \n2014-08-21 10:00:00         35.45         38.89         48.03         47.05   \n2014-08-21 11:00:00         38.89         48.03         47.05         42.15   \n2014-08-21 12:00:00         48.03         47.05         42.15         43.34   \n2014-08-21 13:00:00         47.05         42.15         43.34         39.73   \n2014-08-21 14:00:00         42.15         43.34         39.73         39.03   \n2014-08-21 15:00:00         43.34         39.73         39.03         38.04   \n2014-08-21 16:00:00         39.73         39.03         38.04         36.47   \n2014-08-21 17:00:00         39.03         38.04         36.47         35.12   \n2014-08-21 18:00:00         38.04         36.47         35.12         33.97   \n2014-08-21 19:00:00         36.47         35.12         33.97         33.52   \n2014-08-21 20:00:00         35.12         33.97         33.52         33.52   \n2014-08-21 21:00:00         33.97         33.52         33.52         34.16   \n2014-08-21 22:00:00         33.52         33.52         34.16         35.42   \n2014-08-21 23:00:00         33.52         34.16         35.42         35.56   \n\n                     Price_at_H+8  Price_at_H+9  ...  Price_at_H+14  \\\nTime                                             ...                  \n2014-08-21 00:00:00         49.53         48.47  ...          35.45   \n2014-08-21 01:00:00         48.47         48.47  ...          38.89   \n2014-08-21 02:00:00         48.47         43.21  ...          48.03   \n2014-08-21 03:00:00         43.21         36.01  ...          47.05   \n2014-08-21 04:00:00         36.01         35.09  ...          42.15   \n2014-08-21 05:00:00         35.09         35.45  ...          43.34   \n2014-08-21 06:00:00         35.45         38.89  ...          39.73   \n2014-08-21 07:00:00         38.89         48.03  ...          39.03   \n2014-08-21 08:00:00         48.03         47.05  ...          38.04   \n2014-08-21 09:00:00         47.05         42.15  ...          36.47   \n2014-08-21 10:00:00         42.15         43.34  ...          35.12   \n2014-08-21 11:00:00         43.34         39.73  ...          33.97   \n2014-08-21 12:00:00         39.73         39.03  ...          33.52   \n2014-08-21 13:00:00         39.03         38.04  ...          33.52   \n2014-08-21 14:00:00         38.04         36.47  ...          34.16   \n2014-08-21 15:00:00         36.47         35.12  ...          35.42   \n2014-08-21 16:00:00         35.12         33.97  ...          35.56   \n2014-08-21 17:00:00         33.97         33.52  ...          41.95   \n2014-08-21 18:00:00         33.52         33.52  ...          49.93   \n2014-08-21 19:00:00         33.52         34.16  ...          49.93   \n2014-08-21 20:00:00         34.16         35.42  ...          47.83   \n2014-08-21 21:00:00         35.42         35.56  ...          40.25   \n2014-08-21 22:00:00         35.56         41.95  ...          34.90   \n2014-08-21 23:00:00         41.95         49.93  ...          33.08   \n\n                     Price_at_H+15  Price_at_H+16  Price_at_H+17  \\\nTime                                                               \n2014-08-21 00:00:00          38.89          48.03          47.05   \n2014-08-21 01:00:00          48.03          47.05          42.15   \n2014-08-21 02:00:00          47.05          42.15          43.34   \n2014-08-21 03:00:00          42.15          43.34          39.73   \n2014-08-21 04:00:00          43.34          39.73          39.03   \n2014-08-21 05:00:00          39.73          39.03          38.04   \n2014-08-21 06:00:00          39.03          38.04          36.47   \n2014-08-21 07:00:00          38.04          36.47          35.12   \n2014-08-21 08:00:00          36.47          35.12          33.97   \n2014-08-21 09:00:00          35.12          33.97          33.52   \n2014-08-21 10:00:00          33.97          33.52          33.52   \n2014-08-21 11:00:00          33.52          33.52          34.16   \n2014-08-21 12:00:00          33.52          34.16          35.42   \n2014-08-21 13:00:00          34.16          35.42          35.56   \n2014-08-21 14:00:00          35.42          35.56          41.95   \n2014-08-21 15:00:00          35.56          41.95          49.93   \n2014-08-21 16:00:00          41.95          49.93          49.93   \n2014-08-21 17:00:00          49.93          49.93          47.83   \n2014-08-21 18:00:00          49.93          47.83          40.25   \n2014-08-21 19:00:00          47.83          40.25          34.90   \n2014-08-21 20:00:00          40.25          34.90          33.08   \n2014-08-21 21:00:00          34.90          33.08          33.09   \n2014-08-21 22:00:00          33.08          33.09          35.54   \n2014-08-21 23:00:00          33.09          35.54          52.02   \n\n                     Price_at_H+18  Price_at_H+19  Price_at_H+20  \\\nTime                                                               \n2014-08-21 00:00:00          42.15          43.34          39.73   \n2014-08-21 01:00:00          43.34          39.73          39.03   \n2014-08-21 02:00:00          39.73          39.03          38.04   \n2014-08-21 03:00:00          39.03          38.04          36.47   \n2014-08-21 04:00:00          38.04          36.47          35.12   \n2014-08-21 05:00:00          36.47          35.12          33.97   \n2014-08-21 06:00:00          35.12          33.97          33.52   \n2014-08-21 07:00:00          33.97          33.52          33.52   \n2014-08-21 08:00:00          33.52          33.52          34.16   \n2014-08-21 09:00:00          33.52          34.16          35.42   \n2014-08-21 10:00:00          34.16          35.42          35.56   \n2014-08-21 11:00:00          35.42          35.56          41.95   \n2014-08-21 12:00:00          35.56          41.95          49.93   \n2014-08-21 13:00:00          41.95          49.93          49.93   \n2014-08-21 14:00:00          49.93          49.93          47.83   \n2014-08-21 15:00:00          49.93          47.83          40.25   \n2014-08-21 16:00:00          47.83          40.25          34.90   \n2014-08-21 17:00:00          40.25          34.90          33.08   \n2014-08-21 18:00:00          34.90          33.08          33.09   \n2014-08-21 19:00:00          33.08          33.09          35.54   \n2014-08-21 20:00:00          33.09          35.54          52.02   \n2014-08-21 21:00:00          35.54          52.02          49.08   \n2014-08-21 22:00:00          52.02          49.08          41.95   \n2014-08-21 23:00:00          49.08          41.95          42.45   \n\n                     Price_at_H+21  Price_at_H+22  Price_at_H+23  \nTime                                                              \n2014-08-21 00:00:00          39.03          38.04          36.47  \n2014-08-21 01:00:00          38.04          36.47          35.12  \n2014-08-21 02:00:00          36.47          35.12          33.97  \n2014-08-21 03:00:00          35.12          33.97          33.52  \n2014-08-21 04:00:00          33.97          33.52          33.52  \n2014-08-21 05:00:00          33.52          33.52          34.16  \n2014-08-21 06:00:00          33.52          34.16          35.42  \n2014-08-21 07:00:00          34.16          35.42          35.56  \n2014-08-21 08:00:00          35.42          35.56          41.95  \n2014-08-21 09:00:00          35.56          41.95          49.93  \n2014-08-21 10:00:00          41.95          49.93          49.93  \n2014-08-21 11:00:00          49.93          49.93          47.83  \n2014-08-21 12:00:00          49.93          47.83          40.25  \n2014-08-21 13:00:00          47.83          40.25          34.90  \n2014-08-21 14:00:00          40.25          34.90          33.08  \n2014-08-21 15:00:00          34.90          33.08          33.09  \n2014-08-21 16:00:00          33.08          33.09          35.54  \n2014-08-21 17:00:00          33.09          35.54          52.02  \n2014-08-21 18:00:00          35.54          52.02          49.08  \n2014-08-21 19:00:00          52.02          49.08          41.95  \n2014-08-21 20:00:00          49.08          41.95          42.45  \n2014-08-21 21:00:00          41.95          42.45          39.49  \n2014-08-21 22:00:00          42.45          39.49          36.98  \n2014-08-21 23:00:00          39.49          36.98          51.01  \n\n[24 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price_at_H+0</th>\n      <th>Price_at_H+1</th>\n      <th>Price_at_H+2</th>\n      <th>Price_at_H+3</th>\n      <th>Price_at_H+4</th>\n      <th>Price_at_H+5</th>\n      <th>Price_at_H+6</th>\n      <th>Price_at_H+7</th>\n      <th>Price_at_H+8</th>\n      <th>Price_at_H+9</th>\n      <th>...</th>\n      <th>Price_at_H+14</th>\n      <th>Price_at_H+15</th>\n      <th>Price_at_H+16</th>\n      <th>Price_at_H+17</th>\n      <th>Price_at_H+18</th>\n      <th>Price_at_H+19</th>\n      <th>Price_at_H+20</th>\n      <th>Price_at_H+21</th>\n      <th>Price_at_H+22</th>\n      <th>Price_at_H+23</th>\n    </tr>\n    <tr>\n      <th>Time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2014-08-21 00:00:00</th>\n      <td>32.51</td>\n      <td>32.36</td>\n      <td>31.94</td>\n      <td>31.00</td>\n      <td>33.90</td>\n      <td>38.01</td>\n      <td>38.71</td>\n      <td>39.51</td>\n      <td>49.53</td>\n      <td>48.47</td>\n      <td>...</td>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 01:00:00</th>\n      <td>32.36</td>\n      <td>31.94</td>\n      <td>31.00</td>\n      <td>33.90</td>\n      <td>38.01</td>\n      <td>38.71</td>\n      <td>39.51</td>\n      <td>49.53</td>\n      <td>48.47</td>\n      <td>48.47</td>\n      <td>...</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 02:00:00</th>\n      <td>31.94</td>\n      <td>31.00</td>\n      <td>33.90</td>\n      <td>38.01</td>\n      <td>38.71</td>\n      <td>39.51</td>\n      <td>49.53</td>\n      <td>48.47</td>\n      <td>48.47</td>\n      <td>43.21</td>\n      <td>...</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 03:00:00</th>\n      <td>31.00</td>\n      <td>33.90</td>\n      <td>38.01</td>\n      <td>38.71</td>\n      <td>39.51</td>\n      <td>49.53</td>\n      <td>48.47</td>\n      <td>48.47</td>\n      <td>43.21</td>\n      <td>36.01</td>\n      <td>...</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 04:00:00</th>\n      <td>33.90</td>\n      <td>38.01</td>\n      <td>38.71</td>\n      <td>39.51</td>\n      <td>49.53</td>\n      <td>48.47</td>\n      <td>48.47</td>\n      <td>43.21</td>\n      <td>36.01</td>\n      <td>35.09</td>\n      <td>...</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 05:00:00</th>\n      <td>38.01</td>\n      <td>38.71</td>\n      <td>39.51</td>\n      <td>49.53</td>\n      <td>48.47</td>\n      <td>48.47</td>\n      <td>43.21</td>\n      <td>36.01</td>\n      <td>35.09</td>\n      <td>35.45</td>\n      <td>...</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 06:00:00</th>\n      <td>38.71</td>\n      <td>39.51</td>\n      <td>49.53</td>\n      <td>48.47</td>\n      <td>48.47</td>\n      <td>43.21</td>\n      <td>36.01</td>\n      <td>35.09</td>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>...</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 07:00:00</th>\n      <td>39.51</td>\n      <td>49.53</td>\n      <td>48.47</td>\n      <td>48.47</td>\n      <td>43.21</td>\n      <td>36.01</td>\n      <td>35.09</td>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>...</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 08:00:00</th>\n      <td>49.53</td>\n      <td>48.47</td>\n      <td>48.47</td>\n      <td>43.21</td>\n      <td>36.01</td>\n      <td>35.09</td>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>...</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 09:00:00</th>\n      <td>48.47</td>\n      <td>48.47</td>\n      <td>43.21</td>\n      <td>36.01</td>\n      <td>35.09</td>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>...</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>49.93</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 10:00:00</th>\n      <td>48.47</td>\n      <td>43.21</td>\n      <td>36.01</td>\n      <td>35.09</td>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>...</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>49.93</td>\n      <td>49.93</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 11:00:00</th>\n      <td>43.21</td>\n      <td>36.01</td>\n      <td>35.09</td>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>...</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>49.93</td>\n      <td>49.93</td>\n      <td>47.83</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 12:00:00</th>\n      <td>36.01</td>\n      <td>35.09</td>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>...</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>49.93</td>\n      <td>49.93</td>\n      <td>47.83</td>\n      <td>40.25</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 13:00:00</th>\n      <td>35.09</td>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>...</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>49.93</td>\n      <td>49.93</td>\n      <td>47.83</td>\n      <td>40.25</td>\n      <td>34.90</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 14:00:00</th>\n      <td>35.45</td>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>...</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>49.93</td>\n      <td>49.93</td>\n      <td>47.83</td>\n      <td>40.25</td>\n      <td>34.90</td>\n      <td>33.08</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 15:00:00</th>\n      <td>38.89</td>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>...</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>49.93</td>\n      <td>49.93</td>\n      <td>47.83</td>\n      <td>40.25</td>\n      <td>34.90</td>\n      <td>33.08</td>\n      <td>33.09</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 16:00:00</th>\n      <td>48.03</td>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>...</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>49.93</td>\n      <td>49.93</td>\n      <td>47.83</td>\n      <td>40.25</td>\n      <td>34.90</td>\n      <td>33.08</td>\n      <td>33.09</td>\n      <td>35.54</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 17:00:00</th>\n      <td>47.05</td>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>...</td>\n      <td>41.95</td>\n      <td>49.93</td>\n      <td>49.93</td>\n      <td>47.83</td>\n      <td>40.25</td>\n      <td>34.90</td>\n      <td>33.08</td>\n      <td>33.09</td>\n      <td>35.54</td>\n      <td>52.02</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 18:00:00</th>\n      <td>42.15</td>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>...</td>\n      <td>49.93</td>\n      <td>49.93</td>\n      <td>47.83</td>\n      <td>40.25</td>\n      <td>34.90</td>\n      <td>33.08</td>\n      <td>33.09</td>\n      <td>35.54</td>\n      <td>52.02</td>\n      <td>49.08</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 19:00:00</th>\n      <td>43.34</td>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>...</td>\n      <td>49.93</td>\n      <td>47.83</td>\n      <td>40.25</td>\n      <td>34.90</td>\n      <td>33.08</td>\n      <td>33.09</td>\n      <td>35.54</td>\n      <td>52.02</td>\n      <td>49.08</td>\n      <td>41.95</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 20:00:00</th>\n      <td>39.73</td>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>...</td>\n      <td>47.83</td>\n      <td>40.25</td>\n      <td>34.90</td>\n      <td>33.08</td>\n      <td>33.09</td>\n      <td>35.54</td>\n      <td>52.02</td>\n      <td>49.08</td>\n      <td>41.95</td>\n      <td>42.45</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 21:00:00</th>\n      <td>39.03</td>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>...</td>\n      <td>40.25</td>\n      <td>34.90</td>\n      <td>33.08</td>\n      <td>33.09</td>\n      <td>35.54</td>\n      <td>52.02</td>\n      <td>49.08</td>\n      <td>41.95</td>\n      <td>42.45</td>\n      <td>39.49</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 22:00:00</th>\n      <td>38.04</td>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>...</td>\n      <td>34.90</td>\n      <td>33.08</td>\n      <td>33.09</td>\n      <td>35.54</td>\n      <td>52.02</td>\n      <td>49.08</td>\n      <td>41.95</td>\n      <td>42.45</td>\n      <td>39.49</td>\n      <td>36.98</td>\n    </tr>\n    <tr>\n      <th>2014-08-21 23:00:00</th>\n      <td>36.47</td>\n      <td>35.12</td>\n      <td>33.97</td>\n      <td>33.52</td>\n      <td>33.52</td>\n      <td>34.16</td>\n      <td>35.42</td>\n      <td>35.56</td>\n      <td>41.95</td>\n      <td>49.93</td>\n      <td>...</td>\n      <td>33.08</td>\n      <td>33.09</td>\n      <td>35.54</td>\n      <td>52.02</td>\n      <td>49.08</td>\n      <td>41.95</td>\n      <td>42.45</td>\n      <td>39.49</td>\n      <td>36.98</td>\n      <td>51.01</td>\n    </tr>\n  </tbody>\n</table>\n<p>24 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = recommend.electricity_prices_from_start_time(\"2014-08-21\")\n",
    "price"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  recommendation_date           device  best_launch_hour  \\\n0          2014-08-21     Tumble Dryer                12   \n0          2014-08-21  Washing Machine                12   \n0          2014-08-21       Dishwasher                12   \n\n   no_recommend_flag_activity  no_recommend_flag_usage  recommendation  \\\n0                           0                        0              12   \n0                           0                        0              12   \n0                           0                        0              12   \n\n                         feature_importance_activity  \\\n0                col_name  feature_importance_val...   \n0                col_name  feature_importance_val...   \n0                col_name  feature_importance_val...   \n\n                            feature_importance_usage  \n0                     col_name  feature_importanc...  \n0                        col_name  feature_import...  \n0                   col_name  feature_importance_...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recommendation_date</th>\n      <th>device</th>\n      <th>best_launch_hour</th>\n      <th>no_recommend_flag_activity</th>\n      <th>no_recommend_flag_usage</th>\n      <th>recommendation</th>\n      <th>feature_importance_activity</th>\n      <th>feature_importance_usage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014-08-21</td>\n      <td>Tumble Dryer</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>col_name  feature_importance_val...</td>\n      <td>col_name  feature_importanc...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2014-08-21</td>\n      <td>Washing Machine</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>col_name  feature_importance_val...</td>\n      <td>col_name  feature_import...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2014-08-21</td>\n      <td>Dishwasher</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>col_name  feature_importance_val...</td>\n      <td>col_name  feature_importance_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table= recommend.pipeline(date = \"2014-08-21\", activity_prob_threshold = 0.4,  usage_prob_threshold = 0.3, evaluation=False, weather_sel=False)\n",
    "table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-37-d7723ec455e1>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#recommend.visualize_recommendation_by_device(recommendation_by_decvice_dict)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtable\u001B[0m\u001B[1;31m#.iloc[:,7]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "#recommend.visualize_recommendation_by_device(recommendation_by_decvice_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have a recommendation for the following device: Tumble Dryer\n",
      "\n",
      " Please use the device on the 21.08.2014 at 12:00 oclock because it saves you 8.73 % of costs compared to the mean of the day.\n",
      "\n",
      "We believe you are likely to use the device in the near future since you were  active the last 2 days and have  used the device in the last day. The weather conditions (wind direction:227.2, temperature:73.13) support that recommendation.\n",
      "You have a recommendation for the following device: Washing Machine\n",
      "\n",
      " Please use the device on the 21.08.2014 at 12:00 oclock because it saves you 8.73 % of costs compared to the mean of the day.\n",
      "\n",
      "We believe you are likely to use the device in the near future since you were  active the last 2 days and have  used the device in the last two days. The weather conditions (temperature:73.13, windspeed:21.39) support that recommendation.\n",
      "You have a recommendation for the following device: Dishwasher\n",
      "\n",
      " Please use the device on the 21.08.2014 at 12:00 oclock because it saves you 8.73 % of costs compared to the mean of the day.\n",
      "\n",
      "We believe you are likely to use the device in the near future since you were  active the last 2 days and have  used the device in the last two days. The weather conditions (windspeed:21.39, wind direction:227.2) support that recommendation.\n",
      "We based the recommendation on your past activity and usage of the device. We believe you are active today since you were  active during the last day.The weather conditions (windspeed:27.7, relative humidity:6.0) support that recommendation.\n",
      "For detailed information switch on the diagnostics parameter.\n"
     ]
    }
   ],
   "source": [
    "recommend.visualize_recommendation(table, price)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result of RS: Recommendation + Explanation\n",
    "Note:  Carvalho et. al (2019) mention criteria for Human-friendly explanations that we could include here for reasoning\n",
    "our final explanation approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Discussion \n",
    "\n",
    "### Contributions\n",
    "\n",
    "\n",
    "### Limitations \n",
    "\n",
    "\n",
    "So many different approaches. Available Github Repos but dependencies cause several conflicts due to different package versions.\n",
    "Missing user data. To evaluate the explainability approach from a human perspektive ot would be of cruical importance to measure users trust and acceptance \n",
    "\n",
    "\n",
    "Fidelity is only assesed in terms of accuracy but fidelity is more than that. Potentially, clarity and completeness of fidelity should also be assesed (Zhou et al., 2021).\n",
    "\n",
    "No evaluaation of **Interpretability/ Comprehensibility/ Understandability**; not with proxies because not useful (?) in our case but to evaluate the usefulness of our explantion should be next stept. This critera deals with how well humans actually\n",
    " understand the explanations. Since we have decided on functionally-grounded evaluations\n",
    "we would have to rely on proxies like amount of features/ model size / ...  as a proxy which is not really useful since we can determine that ourselves.\n",
    "\n",
    "https://interpretable-ml-class.github.io/ see evaluation of xai papers --> hints at experiments\n",
    "\n",
    "### Implications\n",
    "\n",
    "### Future Research\n",
    "\n",
    "Gammli- Generalized Additive Modeling with Manifest and Latent Interactions, several recommendations per day.\n",
    "\n",
    "Other metrics see table 2 under attribution- based explanations (Zhou et al., 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "paper: 'Human-in-the-Loop Interpretability Prior'\n",
    "paper: https://dl.acm.org/doi/abs/10.1145/3351095.3375624"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "1. InterpretML: A Unified Framework for Machine Learning Interpretability (H. Nori, S. Jenkins, P. Koch, and R. Caruana 2019)\n",
    "\n",
    "2. Cunningham, Padraig & Delany, Sarah. (2020). k-Nearest Neighbour Classifiers -- 2nd Edition. \n",
    "\n",
    "3. Tianqi Chen and Carlos Guestrin. XGBoost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’16, pages 785–794, New York, NY, USA, 2016. ACM. ISBN 978-1-4503- 4232-2. doi: 10.1145/2939672.2939785. URL http://doi.acm.org/10.1145/2939672. 2939785.\n",
    "\n",
    "4. Breiman, Leo. (2001). Machine Learning, Volume 45, Number 1 - SpringerLink. Machine Learning. 45. 5-32. 10.1023/A:1010933404324. \n",
    "\n",
    "5. Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning\n",
    "and an application to boosting. Journal of Computer and System Sciences, 55(1):119–139,\n",
    "August 1997.\n",
    "\n",
    "6. Chen, Tianqi & Guestrin, Carlos. (2016). XGBoost: A Scalable Tree Boosting System. 785-794. 10.1145/2939672.2939785. \n",
    "\n",
    "7. Peng, Joanne & Lee, Kuk & Ingersoll, Gary. (2002). An Introduction to Logistic Regression Analysis and Reporting. Journal of Educational Research - J EDUC RES. 96. 3-14. 10.1080/00220670209598786. \n",
    "\n",
    "8. Singh, Sengupta, Lakshminarayanan. (2020). Explainable Deep Learning Models in Medical Image Analysis. Journal of Imaging 6, 52.\n",
    "\n",
    "9. Ribeiro, Singh, Guestrin. (2016). \"Why should I trust you?\" Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 1135–1144.\n",
    "\n",
    "10. Lundberg, S. M., & Lee, S. I. (2017, December). A unified approach to interpreting model predictions. In Proceedings of the 31st international conference on neural information processing systems (pp. 4768-4777).\n",
    "\n",
    "11. Lundberg, S. M., Erion, G., Chen, H., DeGrave, A., Prutkin, J. M., Nair, B., ... & Lee, S. I. (2020). From local explanations to global understanding with explainable AI for trees. Nature machine intelligence, 2(1), 56-67.\n",
    "\n",
    "12. Molnar, C. (2021). Interpretable machine learning. https://christophm.github.io/interpretable-ml-book/\n",
    "\n",
    "13. Zhou, J., Gandomi, A. H., Chen, F., & Holzinger, A. (2021). Evaluating the quality of machine learning explanations: A survey on methods and metrics. Electronics, 10(5), 593.\n",
    "\n",
    "14. Robnik-Šikonja, M., & Bohanec, M. (2018). Perturbation-based explanations of prediction models. In Human and machine learning (pp. 159-175). Springer, Cham.\n",
    "\n",
    "15. Carvalho, D. V., Pereira, E. M., & Cardoso, J. S. (2019). Machine learning interpretability: A survey on methods and metrics. Electronics, 8(8), 832.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}