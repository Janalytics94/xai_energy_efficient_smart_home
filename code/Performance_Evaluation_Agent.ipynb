{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Performance Evaluation Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umschreiben\n",
    "To evaluate the performance of our recommender system, we will analyze the system regarding the individual agents’ performance, the cold start problem, the sensitivity to changes in the recommendation hyperparameter and potential energy cost savings. We will introduce a further agent called Evaluation Agent which will perform all evaluation actions.\n",
    "\n",
    "We will perform our evaluation analysis for households 1 to 10 in the REFIT: Electrical Load Measurements data (Murray et at., 2019), to validate our evaluation results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Preparing the Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yaml\n",
    "from agents import Evaluation_Agent\n",
    "from helper_functions import Helper\n",
    "\n",
    "helper = Helper()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "EXPORT_PATH = '../export/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## **2. Preparations for Evaluating the Performance of our Recommender System**\n",
    "### **2.1 Determining User Input**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are able to use our recommender system and evaluate its performance, we need to specify the required user inputs (i.e. active appliances, shiftable devices and the consumption threshold). For specifying which of the devices in the respective household will be determined as active appliances and shiftable devices, we look at the description of the devices provided in the readme file and categorize the devices according to our definitions of the categories. Furthermore, we validate that the used devices do not contain any noise in their consumption data and remove devices which contain noise, i.e. consume energy constantly over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = DATA_PATH+'REFIT_Readme.txt'\n",
    "readme = helper.load_txt(readme)\n",
    "start = readme.rfind('House 1\\n')\n",
    "end = readme.find('House 11\\n')\n",
    "print(readme[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Shiftable Devices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual input, determined using information provided in the readme\n",
    "# validated in the next step using the validate thresholds functionality\n",
    "shiftable_devices = {\n",
    "    1: ['Tumble Dryer', 'Washing Machine', 'Dishwasher'],\n",
    "    2: ['Washing Machine', 'Dishwasher'],\n",
    "    3: ['Tumble Dryer', 'Washing Machine', 'Dishwasher'],\n",
    "    4: ['Washing Machine (1)', 'Washing Machine (2)'],\n",
    "    5: ['Tumble Dryer'], # , 'Washing Machine' --> consumes energy constantly; , 'Dishwasher' --> noise at 3am\n",
    "    6: ['Washing Machine', 'Dishwasher'],\n",
    "    7: ['Tumble Dryer', 'Washing Machine', 'Dishwasher'],\n",
    "    8: ['Washing Machine'], # 'Dryer' --> consumes constantly\n",
    "    9: ['Washer Dryer', 'Washing Machine', 'Dishwasher'], \n",
    "    10: ['Washing Machine'] #'Dishwasher'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Active Appliances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1611869179830,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "XH42w1_HyeMs"
   },
   "outputs": [],
   "source": [
    "# manual input, determined using information provided in the readme\n",
    "# validated in the next step using the validate thresholds functionality\n",
    "active_appliances = {\n",
    "    1: deepcopy(shiftable_devices[1]) + ['Television Site', 'Computer Site'],\n",
    "    2: deepcopy(shiftable_devices[2]) + ['Television', 'Microwave', 'Toaster', 'Hi-Fi', 'Kettle'],\n",
    "    3: deepcopy(shiftable_devices[3]) + ['Toaster', 'Television', 'Microwave', 'Kettle'],\n",
    "    4: deepcopy(shiftable_devices[4]) + ['Television Site', 'Kettle'], #'Microwave', 'Computer Site' --> consume energy constantly \n",
    "    5: deepcopy(shiftable_devices[5]) + ['Television Site', 'Combination Microwave', 'Kettle', 'Toaster'], # 'Computer Site', --> consumes energy constantly\n",
    "    6: deepcopy(shiftable_devices[6]) + ['MJY Computer', 'Kettle', 'Toaster'], #, 'PGM Computer', 'Television Site' 'Microwave' --> consume energy constantly \n",
    "    7: deepcopy(shiftable_devices[7]) + ['Television Site', 'Toaster', 'Kettle'],\n",
    "    8: deepcopy(shiftable_devices[8]) + ['Toaster', 'Kettle'], # 'Television Site', 'Computer' --> consume energy constantly\n",
    "    9: deepcopy(shiftable_devices[9]) + ['Microwave', 'Kettle'], #'Television Site', 'Hi-Fi' --> consume energy constantly\n",
    "    10: deepcopy(shiftable_devices[10]) + ['Magimix (Blender)', 'Microwave'] # 'Television Site' --> consume energy constantly\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Energy Consumption Threshold**\n",
    "\n",
    "Our Preparation Agent will require the energy consumption threshold, which will determine if a device was used in a given period. This threshold will allow to reduce the impact of noise in the data. We will determine the optimal thresholds for the households using the Preparation Agent’s validate thresholds method. To demonstrate how noise in the consumption data occurs, we call the validate thresholds method for household 1. The consumption data regarding the Television Site in household 1 seems to contain daily noise around 3 am. We will choose the optimal threshold, such that the noise is removed from the data.\n",
    "\n",
    "Furthermore, we will create our initial evaluation configuration file for each household which will contain the specified user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating the thresholds for household 1 to show noise in the data\n",
    "household_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the config including the user input\n",
    "config =  {'data': {'household': deepcopy(household_id)}}\n",
    "config['user_input'] = {\n",
    "    'shiftable_devices': deepcopy(shiftable_devices[config['data']['household']]),\n",
    "    'active_appliances': deepcopy(active_appliances[config['data']['household']])\n",
    "}\n",
    "# ada acts weird, logit is alright, random forest is alright, knn is okay, xgboost ok\n",
    "# initializing the evaluation agent\n",
    "evaluation = Performance_Evaluation_Agent(DATA_PATH, 'logit', config, load_data=True, weather_sel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparation = evaluation.preparation\n",
    "\n",
    "# Data-Preparation\n",
    "df_th = preparation.truncate(preparation.input)\n",
    "df_th = preparation.scale(df_th)\n",
    "df_th = helper.aggregate(df_th, '60T')\n",
    "\n",
    "# Graphical analysis of candidate thresholds\n",
    "thresholds = [0] + list(np.geomspace(.01, .4, 5))\n",
    "preparation.validate_thresholds(df_th, thresholds, config['user_input']['active_appliances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    1: 0.15,\n",
    "    2: 0.01,\n",
    "    3: 0.01, \n",
    "    4: 0.01, \n",
    "    5: 0.025,\n",
    "    6: 0.065, \n",
    "    7: 0.01, \n",
    "    8: 0.01, # washing machine over night\n",
    "    9: 0.01, \n",
    "    10: 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### **2.2 Running our Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are able to analyze the performance of our recommender system, we need to calculate all outputs of all our agents and all recommendations possible based on the available data. To conveniently compute these outputs and recommendations for the households, we added a pipeline method to the Evaluation Agent which allows to run every agent of our recommender system for every available date iteratively. We will demonstrate its functionality by creating the recommendations for household 3. \n",
    "\n",
    "Additionally, we will use a further method of the Evaluation Agent to receive the default configuration for evaluating our recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the config including the user input\n",
    "config =  {'data': {'household': deepcopy(household_id)}}\n",
    "config['user_input'] = {\n",
    "    'shiftable_devices': deepcopy(shiftable_devices[config['data']['household']]),\n",
    "    'active_appliances': deepcopy(active_appliances[config['data']['household']]),\n",
    "    'threshold': deepcopy(thresholds[config['data']['household']])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Preparing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_sel = False\n",
    "# calling the evaluation agent\n",
    "evaluation = Performance_Evaluation_Agent(DATA_PATH, 'logit',config, weather_sel=weather_sel, xai = False)\n",
    "evaluation.get_default_config('preparation')\n",
    "evaluation.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.pipeline('preparation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.df['activity'][100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.df['usage'][100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.df['load'][335:340]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Creating all recommendations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.get_default_config(['activity', 'usage', 'load'])\n",
    "evaluation.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation.pipeline(['activity','usage','load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.pipeline('recommendation', activity_threshold=0.625, usage_threshold=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.output['recommendation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation.output['recommendation']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is adapted such that household id, model type (actitivty, usage) and weather sel is given in name\n",
    "evaluation.dump(EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## **3. Evaluating the Performance of our Recommender System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goals for evaluating our recommender systems performance are to measure the performance of the individual agents (i.e. Activity Agent, Usage Agent, Load Agent), to quantify the cold start problem of our recommender system, to analyze the sensitivity of our system to changes in the recommendation hyperparameter (i.e. activity threshold and usage threshold) as well as to calculate the potential energy cost savings for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1. Evaluating the Performance of the Individual Agents** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the performance the Activity Agent, the Usage Agent and the Load Agent, we will use the agents’ own evaluation methods. Hence, evaluation method of the Activity Agent and the Usage Agent will calculate the Area under the ROC curve (i.e. AUC score). It will use all daily predictions received from running the pipeline from above, combine the predictions to one dataset and use this dataset to calculate the AUC scores. For the Load Agent, its evaluation method will extract all load profiles for the actual devices runs in the data and compare them to the respective typical load profile which is available at the date of the actual run. To summarize the performance the evaluation method will calculate the mean squared error for all device runs and will aggregate the scores to a single score by averaging over all device runs (i.e. MSE score). After finishing the evaluation of the individual agents’ performance, we will receive one AUC score for the Activity Agent per household as well as one usage AUC score and one load MSE score per shiftable device of the respective household.\n",
    "\n",
    "All necessary steps to calculate the performance of the individual agents can be called using a single method of the Evaluation Agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After we have run the pipeline and gotten the files we need\n",
    "we can load it again with these functions to run the evaluation per household:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-36-2d80e232d2a8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;31m# initializing the agent\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[0mevaluation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mPerformance_Evaluation_Agent\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDATA_PATH\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmodel_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel_type\u001B[0m \u001B[1;33m,\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mload_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mload_files\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfiles\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweather_sel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mweather_sel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mxai\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mxai\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[0mevaluation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minit_agents\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\xai_energy_efficient_smart_home\\code\\agents.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, DATA_PATH, model_type, config, load_data, load_files, weather_sel, xai)\u001B[0m\n\u001B[0;32m   1647\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweather_sel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mweather_sel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1648\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxai\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxai\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1649\u001B[1;33m         \u001B[0mhouse_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhelper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_household\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDATA_PATH\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"data\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"household\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweather_sel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mweather_sel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1650\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mload_data\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1651\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreparation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0magents\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPreparation_Agent\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhouse_df\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\xai_energy_efficient_smart_home\\code\\helper_functions.py\u001B[0m in \u001B[0;36mload_household\u001B[1;34m(self, REFIT_dir, house_id, weather_sel)\u001B[0m\n\u001B[0;32m    118\u001B[0m         \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_column_labels\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreadme\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 120\u001B[1;33m         \u001B[0mhouse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    121\u001B[0m         \u001B[0mhouse\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrename\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mhouse_id\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    122\u001B[0m         \u001B[0mhouse\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDatetimeIndex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhouse\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Time'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    486\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    487\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 488\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    489\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    490\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1045\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1046\u001B[0m         \u001B[0mnrows\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"nrows\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1047\u001B[1;33m         \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcol_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1048\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1049\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mindex\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    221\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlow_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m                 \u001B[0mchunks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_low_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m                 \u001B[1;31m# destructive to chunks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_concatenate_chunks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchunks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mParserError\u001B[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "xai= False\n",
    "weather_sel = True\n",
    "household_id = 3\n",
    "model_type = 'knn' #atm default with same model type\n",
    "\n",
    "config = json.load(open(EXPORT_PATH + str(household_id) + '_' + str(model_type) + '_' + str(model_type) +'_' + str(weather_sel) +'_config.json', 'r'))\n",
    "files = ['df.pkl', 'output.pkl']\n",
    "files = [f\"{EXPORT_PATH}{household_id}_{model_type}_{model_type}_{weather_sel}_{file}\" for file in files]\n",
    "\n",
    "# initializing the agent\n",
    "evaluation = Performance_Evaluation_Agent(DATA_PATH,model_type=model_type ,config=config, load_data=True, load_files=files, weather_sel=weather_sel,xai= xai)\n",
    "evaluation.init_agents()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To do for evaluation:\n",
    "We have to run this function for each of the ML models seperately\n",
    "and with the setting weather_sel.\n",
    "Note: atm still only evaluate first free rows in test set.\n",
    "Also: time is mean of: explainer calculation + row prediction for one day\n",
    "--> change timing? (e.g. seperately for explainer and average per row; or seperately explainer and day)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scores, predictions_list_activity, predictions_list_usage = evaluation.get_agent_scores(xai=xai)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we will have to save the output from agent_scores\n",
    "for each configuration by dumping it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation.dump(EXPORT_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "**Converting agent scores to tabular structure for comparison with further households**\n",
    "\n",
    "As each household has different shiftable devices, we will assign each shiftable device in each household with an integer index. Using these indices, we are able to create an overview on the individual agent scores over different households. To connect the indices with the actual device name we will create a legend for the shiftable devices using our helper functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "helper.shiftable_device_legend(EXPORT_PATH).fillna('-')\n",
    "agent_scores = {}\n",
    "agent_scores[household_id] = evaluation.agent_scores_to_summary()\n",
    "helper.concat_household_scores(agent_scores).round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(EXPORT_PATH+'agent-scores.pkl', 'wb') as file:\n",
    "    pickle.dump(agent_scores, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XAI PERFORMANCE EVAL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "xai= True\n",
    "weather_sel = True\n",
    "household_id = 3\n",
    "model_type = 'xgboost'\n",
    "\n",
    "RESULT_PATH = str(EXPORT_PATH)+str(household_id)+ \"_\" + str(model_type) + \"_\" + str(model_type) + \"_\" + str(weather_sel) + \"_\"\n",
    "RESULT_PATH\n",
    "\n",
    "with open(RESULT_PATH + 'predictions.pkl','rb') as path_name:\n",
    "    predictions = pd.read_pickle(path_name) #pickle.load\n",
    "with open(RESULT_PATH + 'predictions_usage.pkl','rb') as path_name:\n",
    "    predictions_usage = pd.read_pickle(path_name) #pickle.load\n",
    "with open(RESULT_PATH + 'scores.pkl','rb') as path_name:\n",
    "    scores = pd.read_pickle(path_name) #pickle.load\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "del predictions_usage['Dishwasher'][1][-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "config = json.load(open(EXPORT_PATH + str(household_id) + '_' + str(model_type) + '_' + str(model_type) +'_' + str(weather_sel) +'_config.json', 'r'))\n",
    "files = ['df.pkl', 'output.pkl']\n",
    "files = [f\"{EXPORT_PATH}{household_id}_{model_type}_{model_type}_{weather_sel}_{file}\" for file in files]\n",
    "\n",
    "# initializing the agent\n",
    "evaluation = Evaluation_Agent(DATA_PATH,model_type=model_type ,config=config, load_data=True, load_files=files, weather_sel=weather_sel,xai= xai)\n",
    "evaluation.init_agents()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predictions to metrics function to also get dict for explainability metrics.\n",
    "Atm: very bad because wrong assignment since only the first two are tried\n",
    "for lime and shap and they do not correspond to the correct value here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ACTIVITY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "{'activity_lime_auc_true': 0.8377714161413143,\n 'activity_shap_auc_true': 0.8365792028592114,\n 'activity_lime_auc_pred': 0.797077010098011,\n 'activity_shap_auc_pred': 1.0,\n 'activity_lime_MSEE': 0.008416774345090514,\n 'activity_shap_MSEE': 1.6617061492302497e-19}"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to do: code correct? if so input into agents.py\n",
    "# first calculate metrics and add to dict similar to scores\n",
    "xai_scores = evaluation.predictions_to_xai_metrics(predictions, activity_threshold=0.5, usage_threshold=0.5)\n",
    "xai_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Usage Tumble"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "{'usage_lime_auc_true': 0.6431896933339438,\n 'usage_shap_auc_true': 0.9333241745661034,\n 'usage_lime_auc_pred': 0.6368289983397897,\n 'usage_shap_auc_pred': 1.0,\n 'usage_lime_MSEE': 0.0006341714456338712,\n 'usage_shap_MSEE': 4.174034519359635e-18}"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xai_scores = evaluation.predictions_to_xai_metrics_usage(predictions_usage['Tumble Dryer'], activity_threshold=0.5, usage_threshold=0.5)\n",
    "xai_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Usage Washing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "{'usage_lime_auc_true': 0.6847386759581882,\n 'usage_shap_auc_true': 0.9378087495160665,\n 'usage_lime_auc_pred': 0.6463449457452883,\n 'usage_shap_auc_pred': 1.0,\n 'usage_lime_MSEE': 0.0013808035698578325,\n 'usage_shap_MSEE': 1.7496814927868447e-19}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xai_scores = evaluation.predictions_to_xai_metrics_usage(predictions_usage['Washing Machine'], activity_threshold=0.5, usage_threshold=0.5)\n",
    "xai_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Usage Dishwasher"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "{'usage_lime_auc_true': 0.7009602864583333,\n 'usage_shap_auc_true': 0.9347981770833332,\n 'usage_lime_auc_pred': 0.6717263820353288,\n 'usage_shap_auc_pred': 1.0,\n 'usage_lime_MSEE': 0.014519594346157572,\n 'usage_shap_MSEE': 6.800134554348153e-18}"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xai_scores = evaluation.predictions_to_xai_metrics_usage(predictions_usage['Dishwasher'], activity_threshold=0.5, usage_threshold=0.5)\n",
    "xai_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SCORES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "{'activity_auc': 0.8365792548494119,\n 'time_mean_lime_activity': 310.55098630378603,\n 'time_mean_shap_activity': 0.7166331053700686,\n 'usage_auc': {'Tumble Dryer': 0.9339595914411392,\n  'Washing Machine': 0.9379475301633438,\n  'Dishwasher': 0.9354556446480845},\n 'time_mean_lime_usage': 10.221833048388362,\n 'time_mean_shap_usage': 0.23169335816055536,\n 'load_mse': {'Tumble Dryer': 24907.49902412644,\n  'Washing Machine': 890.3298548744685,\n  'Dishwasher': 314.8394453857796}}"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def xai_prediction_to_summary(self):\n",
    "    import pandas as pd\n",
    "    xai_scores = self.xai_scores\n",
    "\n",
    "    summary = {}\n",
    "    summary['activity_lime_auc'] = pd.DataFrame()\n",
    "    summary['activity_shap_auc'] = pd.DataFrame()\n",
    "    summary['usage_lime_auc'] = pd.DataFrame()\n",
    "    summary['usage_shap_auc'] = pd.DataFrame()\n",
    "\n",
    "    household_id = self.config['data']['household']\n",
    "    devices = self.config['user_input']['shiftable_devices']\n",
    "\n",
    "    # activity\n",
    "    summary['activity_lime_auc'].loc[household_id, '-'] = predictions['activity_lime_auc']\n",
    "    # usage\n",
    "    i = 0\n",
    "    for device in devices:\n",
    "        summary['usage_auc'].loc[household_id, i] = scores['usage_auc'][device]\n",
    "        i += 1\n",
    "    # load\n",
    "    i = 0\n",
    "    for device in devices:\n",
    "        summary['load_mse'].loc[household_id, i] = scores['load_mse'][device]\n",
    "        i += 1\n",
    "\n",
    "    summary['activity_auc'].index.name = 'household'\n",
    "    summary['usage_auc'].index.name = 'household'\n",
    "    summary['load_mse'].index.name = 'household'\n",
    "    summary['usage_auc'].columns.name = 'device'\n",
    "    summary['load_mse'].columns.name = 'device'\n",
    "    return summary\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Evaluating the Sensitivity of our Recommender System to Changes in the Recommendation Hyperparameter\n",
    "\n",
    "The ultimate goal of evaluating our framework is to analyze the potential energy cost savings for our user. To evaluate the cost savings for each recommendation, we will start by determining whether a recommendation provided by framework would be acceptable for the user. A recommendation is considered acceptable, if both the activity target and the device usage target are positive for the recommended starting hour and device. Furthermore, we will calculate the cost savings for the acceptable recommendations. These cost savings are determined by the cost for running the device according to our recommendation and the cost for the relevant run which the user performed without receiving our recommendation. If the user ran the device multiple times on the day for which a recommendation was provided, the relevant run was defined as the run for which the starting time is closest to the recommended starting hour. As we use industry day-ahead energy prices in our recommender system, the absolute savings do not represent a realistic prediction of cost savings on the household level. However, the relative saving which compares the energy costs while accepting the recommendation to the energy costs without the recommendation is a more appropriate to measure our recommender system’s performance.\n",
    "\n",
    "Since we calculate the cost savings for each recommendation, we will aggregate our evaluation results to summarize the performance of our recommender system to a few metrics. The performance will be determined by the number of recommendations provided, the acceptance rate of the provided recommendations, the total savings and the relative savings.\n",
    "\n",
    "For creating our recommendations, we need to specify the two hyperparameter, i.e. activity threshold and usage threshold. We tune the parameters using a grid search over candidate thresholds. We will use the results from the grid search to analyze the sensitivity of the recommendation timing and the performance metrics to changes in the hyperparameter as well as determining optimal values for these parameters. We defined the optimal hyperparameter as the parameter combination which will lead to the highest total savings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Savings for Given Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.evaluate(0.625, 0.125)\n",
    "list(evaluation.results.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.results_to_summary().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search over Candidate Hyperparameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 8\n",
    "activity_thresholds = np.linspace(1/(steps), 1, steps)[:-1]\n",
    "usage_thresholds = np.linspace(1/steps, 1, steps)[:-1]\n",
    "print(f\"[grid search] candidate thresholds {activity_thresholds}\\n\")\n",
    "time.sleep(0.3)\n",
    "evaluation.grid_search(activity_thresholds, usage_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.results_to_summary().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Sensitivity of the Timing of Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the results from the grid search to analyze the changes in recommendation timing for different hyperparameter. As the device usage is predicted on a daily level, changes in the usage threshold will not lead to changes in the hours in which the recommendation will be made. Therefore, we will analyze the changes in recommendation timings for a constant usage threshold and a changing activity threshold. \n",
    "\n",
    "Additionally, we will compare the timing of the recommendations to the average energy price per hour and the average activity of the user per hour to identify potential patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the recommendation timings to average activity per hour and average price per hour\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "prices = pd.DataFrame(evaluation.price.input)\n",
    "prices['hour'] = list(prices.index.map(lambda x: x.hour))\n",
    "prices.groupby(by='hour').mean().plot(ax=axes[0])\n",
    "axes[0].set(title='average price per hour', ylabel='average price');\n",
    "\n",
    "activity = evaluation.activity.input[['hour', 'activity']]\n",
    "activity.groupby(by='hour').mean().plot(ax=axes[1])\n",
    "axes[1].set(title='average activity per hour', ylabel='average avtivity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Sensitivity of our Performance Measures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = int(np.ceil(np.sqrt(evaluation.results_to_summary().shape[1])))\n",
    "n_rows = int(np.ceil(evaluation.results_to_summary().shape[1] / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(18,10))\n",
    "axes = axes.reshape(-1,)\n",
    "\n",
    "columns = list(evaluation.results_to_summary().columns)\n",
    "for i in range(axes.shape[0]):\n",
    "    try:\n",
    "        col = columns[i]\n",
    "        sensitivity = evaluation.get_sensitivity(col)\n",
    "        sns.heatmap(sensitivity, ax=axes[i])\n",
    "        axes[i].set(title=f\"heatmap: {col}\")\n",
    "    except IndexError:\n",
    "        axes[i].remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Determining the Optimal Recommendation Hyperparameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_thresholds = evaluation.get_optimal_thresholds()\n",
    "optimal_thresholds_index = evaluation.thresholds_to_index()\n",
    "optimal_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results = results.append(evaluation.optimal_result_to_summary())\n",
    "results = results[['activity_threshold', 'usage_threshold', 'acceptable', 'n_recommendations', 'relative_savings_mean', 'total_savings']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing of optimal recommendations\n",
    "evaluation.results[optimal_thresholds_index]['recommendation'].hist();\n",
    "plt.ylabel('recommendation count')\n",
    "plt.xlabel('hour of the day')\n",
    "plt.title('Timing of optimal recommendations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.dump(EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## **4. Performing the Evaluation on Multiple Households**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate our findings, we will perform the evaluation steps presented above on households 1 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cold start: metrics\n",
    "euclidean = scipy.spatial.distance.euclidean\n",
    "magnitude = lambda v: np.sqrt(np.dot(v.values.reshape(-1), v.values.reshape(-1)))\n",
    "norm_euclidean = lambda y_true, y_hat: euclidean(y_true, y_hat) / magnitude(y_true)\n",
    "\n",
    "metrics =     {\n",
    "    'activity': 'auc',\n",
    "    'usage': 'auc',\n",
    "    'load': 'norm_euclidean'\n",
    "}\n",
    "\n",
    "# cold start: tolerance values\n",
    "tolerance = [0.05, 0.1, 0.15, 0.2, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 8\n",
    "activity_thresholds = np.linspace(1/(steps), 1, steps)[:-1]\n",
    "usage_thresholds = np.linspace(1/steps, 1, steps)[:-1]\n",
    "print(f\"[grid search] candidate thresholds {list(activity_thresholds)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "households = shiftable_devices.keys()\n",
    "\n",
    "agent_scores = {}\n",
    "cold_start_days = {}\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for household_id in households:\n",
    "    \n",
    "    # creating the configuration file\n",
    "    config =  {'data': {'household': deepcopy(household_id)}}\n",
    "    config['user_input'] = {\n",
    "        'shiftable_devices': deepcopy(shiftable_devices[config['data']['household']]),\n",
    "        'active_appliances': deepcopy(active_appliances[config['data']['household']]),\n",
    "        'threshold': deepcopy(thresholds[config['data']['household']])\n",
    "    }\n",
    "\n",
    "    # initializing the evaluation agent\n",
    "    evaluation = Evaluation_Agent(DATA_PATH, config)\n",
    "\n",
    "    # running the pipeline\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # preparing the input data\n",
    "    evaluation.get_default_config('preparation')\n",
    "    evaluation.pipeline('preparation')\n",
    "    \n",
    "    # creating all recommendations\n",
    "    evaluation.get_default_config(['activity', 'usage', 'load'])\n",
    "    evaluation.pipeline(['activity', 'usage', 'load'])\n",
    "\n",
    "    # storing intermediary results\n",
    "    evaluation.dump(EXPORT_PATH)\n",
    "    \n",
    "    # evaluating the performance of the induvidual agents\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    evaluation.get_agent_scores()\n",
    "    agent_scores[household_id] = evaluation.agent_scores_to_summary()\n",
    "    \n",
    "    # evaluating the performance of the induvidual agents\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    evaluation.get_cold_start_scores(fn={'load': norm_euclidean})\n",
    "    evaluation.get_cold_start_days(tolerance_values=tolerance)\n",
    "    cold_start_days[household_id] = evaluation.cold_start_to_summary(tolerance)\n",
    "    \n",
    "    # evaluating the performance of the framework + parameter tuning\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    evaluation.grid_search(activity_thresholds, usage_thresholds)\n",
    "    results = results.append(evaluation.optimal_result_to_summary())\n",
    "    \n",
    "    # storing the results\n",
    "    evaluation.dump(EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = helper.shiftable_device_legend(EXPORT_PATH)\n",
    "legend.fillna('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Performance of the Individual Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_PATH+'agent-scores.pkl', 'wb') as file:\n",
    "    pickle.dump(agent_scores, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_scores_summary = helper.concat_household_scores(agent_scores).round(2).fillna('-')\n",
    "agent_scores_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Cold Start Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_start_days_df = helper.concat_household_scores(cold_start_days)\n",
    "\n",
    "tolerance_index = 2\n",
    "print(f\"[cold start] tolerance value: {tolerance[tolerance_index]}\")\n",
    "\n",
    "for i in range(cold_start_days_df.shape[0]):\n",
    "    for j in range(cold_start_days_df.shape[1]):\n",
    "        try:\n",
    "            cold_start_days_df.iloc[i,j] = cold_start_days_df.iloc[i,j][tolerance_index]\n",
    "        except TypeError:\n",
    "            pass\n",
    "cold_start_days_df.fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_PATH+'cold-start-days.pkl', 'wb') as file:\n",
    "    pickle.dump(cold_start_days, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Perfomance of our Recommender System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[['activity_threshold', 'usage_threshold', 'acceptable', 'n_recommendations', 'relative_savings_mean', 'total_savings']]\n",
    "results.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPORT_PATH+'results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## **Reference List**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Murray, D., Stankovic, L., & Stankovic, V. (2017). An electrical load measurements datasetof united kingdom households from a two-year longitudinal study [data set]. *Scientific Data*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## **Appendix A1: Complete Evaluation Agent Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation_Agent:\n",
    "    def __init__(self, DATA_PATH, config, load_data=True, load_files=None):\n",
    "        import agents\n",
    "        from helper_functions import Helper\n",
    "        import pandas as pd\n",
    "\n",
    "        helper = Helper()\n",
    "\n",
    "        self.config = config\n",
    "        self.preparation = (agents.Preparation_Agent(helper.load_household(DATA_PATH, config[\"data\"][\"household\"]))\n",
    "            if load_data\n",
    "            else None\n",
    "        )\n",
    "        self.price = (\n",
    "            agents.Price_Agent(helper.create_day_ahead_prices_df(DATA_PATH, \"Day-ahead Prices_201501010000-201601010000.csv\"))\n",
    "            if load_data\n",
    "            else None\n",
    "        )\n",
    "        self.activity = None\n",
    "        self.load = None\n",
    "        for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "            name = (\"usage_\"+ device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "            exec(f\"self.{name} = None\")\n",
    "        self.recommendation = None\n",
    "        self.df = {}\n",
    "        self.output = {}\n",
    "        self.errors = {}\n",
    "        self.agent_scores = {} \n",
    "        self.cold_start_scores = {}\n",
    "        #self.true_loads = None\n",
    "        self.results = {}\n",
    "        self.cold_start_days = pd.DataFrame()\n",
    "        if load_files != None:\n",
    "            self.load_from_drive(load_files)\n",
    "\n",
    "    # helper: loading and storing intermediary results and further helper\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def _load_object(self, filename):\n",
    "        import pickle\n",
    "        import json\n",
    "        import yaml\n",
    "\n",
    "        # using a command dict as a if-list\n",
    "        commands = {\n",
    "            \"pkl\": f\"pickle.load(open('{filename}', 'rb'))\",\n",
    "            \"json\": f\"json.load(open('{filename}', 'r'))\",\n",
    "            \"yaml\": f\"yaml.load(open('{filename}', 'r'), Loader = yaml.Loader)\",\n",
    "        }\n",
    "\n",
    "        *_, name, ftype = filename.split(\".\")\n",
    "        name = name[name.rfind(\"_\") + 1 :]\n",
    "        obj = eval(commands[ftype])\n",
    "        self[name] = obj\n",
    "\n",
    "    def load_from_drive(self, files):\n",
    "        files = [files] if type(files) != list else files\n",
    "        for filename in files:\n",
    "            self._load_object(filename)\n",
    "\n",
    "    def dump(self, EXPORT_PATH):\n",
    "        import json\n",
    "        import yaml\n",
    "        import pickle\n",
    "\n",
    "        # storing the current configuration\n",
    "        json.dump(self.config, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + \"_config.json\",\"w\"), indent=4)\n",
    "\n",
    "        # storing the prepared data\n",
    "        if self.df != {}:\n",
    "            pickle.dump(self.df, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + \"_df.pkl\", \"wb\"))\n",
    "\n",
    "        # storing the agents' output\n",
    "        if self.output != {}:\n",
    "            pickle.dump(self.output, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + \"_output.pkl\", \"wb\"))\n",
    "            \n",
    "        # storing the results\n",
    "        if self.results != {}:\n",
    "            pickle.dump(self.results, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + \"_results.pkl\", \"wb\"))\n",
    "            \n",
    "    def __getitem__(self, item):\n",
    "        return eval(f\"self.{item}\")\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        exec(f\"self.{key} = value\")\n",
    "\n",
    "    def _format_time(self, seconds):\n",
    "        return \"{:02.0f}\".format(seconds // 60) + \":\" + \"{:02.0f}\".format(seconds % 60)\n",
    "    \n",
    "    def _get_agent_names(self):\n",
    "        devices = self.config[\"user_input\"][\"shiftable_devices\"]\n",
    "        names = [\"activity\", \"load\"] + [\"usage_\"+ str(device).replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower() for device in devices]\n",
    "        return names\n",
    "\n",
    "    \n",
    "    # creating the default configuration\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def get_default_config(self, agents):\n",
    "        if type(agents) != list:\n",
    "            agents = [agents]\n",
    "        \n",
    "        agents = [agent.lower() for agent in agents]\n",
    "        for agent in agents:\n",
    "            exec(f\"self._get_default_{agent}_config()\")     \n",
    "            \n",
    "    def _get_default_preparation_config(self):\n",
    "        from copy import deepcopy\n",
    "\n",
    "        # preparation\n",
    "        self.config[\"preparation\"] = {}\n",
    "        ## preparation: activity agent\n",
    "        self.config[\"preparation\"][\"activity\"] = {\n",
    "            \"truncate\": {\"features\": \"all\", \"factor\": 1.5, \"verbose\": 0},\n",
    "            \"scale\": {\"features\": \"all\", \"kind\": \"MinMax\", \"verbose\": 0},\n",
    "            \"aggregate\": {\"resample_param\": \"60T\"},\n",
    "            \"activity\": {\n",
    "                \"active_appliances\": deepcopy(self.config[\"user_input\"][\"active_appliances\"]),\n",
    "                \"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"]),\n",
    "            },\n",
    "            \"time\": {\"features\": [\"hour\", \"day_name\"]},\n",
    "            \"activity_lag\": {\"features\": [\"activity\"], \"lags\": [24, 48, 72]},\n",
    "        }\n",
    "        ## preparation: usage agent\n",
    "        self.config[\"preparation\"][\"usage\"] = {\n",
    "            \"truncate\": {\"features\": \"all\", \"factor\": 1.5, \"verbose\": 0},\n",
    "            \"scale\": {\"features\": \"all\", \"kind\": \"MinMax\", \"verbose\": 0},\n",
    "            \"activity\": {\n",
    "                \"active_appliances\": deepcopy(self.config[\"user_input\"][\"active_appliances\"]),\n",
    "                \"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"]),\n",
    "            },\n",
    "            \"aggregate_hour\": {\"resample_param\": \"60T\"},\n",
    "            \"aggregate_day\": {\"resample_param\": \"24H\"},\n",
    "            \"time\": {\"features\": [\"hour\", \"day_name\"]},\n",
    "            \"shiftable_devices\": deepcopy(self.config[\"user_input\"][\"shiftable_devices\"]),\n",
    "            \"device\": {\"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"])},\n",
    "        }\n",
    "        ## preparation: load agent\n",
    "        self.config[\"preparation\"][\"load\"] = {\n",
    "            \"truncate\": {\"features\": \"all\", \"factor\": 1.5, \"verbose\": 0},\n",
    "            \"scale\": {\"features\": \"all\", \"kind\": \"MinMax\", \"verbose\": 0},\n",
    "            \"aggregate\": {\"resample_param\": \"60T\"},\n",
    "            \"shiftable_devices\": deepcopy(self.config[\"user_input\"][\"shiftable_devices\"]),\n",
    "            \"device\": {\"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"])},\n",
    "        }\n",
    "\n",
    "    def _get_default_activity_config(self):\n",
    "        from copy import deepcopy\n",
    "        \n",
    "        if (self.activity == None):\n",
    "            self.init_agents()\n",
    "        self._get_dates()\n",
    "        self.config[\"activity\"] = {\n",
    "            \"model_type\": \"logit\",\n",
    "            \"split_params\": {\n",
    "                \"train_start\": deepcopy(self.config[\"data\"][\"start_dates\"][\"activity\"]),\n",
    "                \"test_delta\": {\"days\": 1, \"seconds\": -1},\n",
    "                \"target\": \"activity\",\n",
    "            },\n",
    "        }\n",
    "        \n",
    "    def _get_default_load_config(self):\n",
    "        from copy import deepcopy\n",
    "        \n",
    "        if (self.load == None):\n",
    "            self.init_agents()\n",
    "        self._get_dates()\n",
    "        self.config[\"load\"] = {\n",
    "            \"shiftable_devices\": deepcopy(self.config[\"user_input\"][\"shiftable_devices\"])\n",
    "        }\n",
    "        \n",
    "    def _get_default_usage_config(self):\n",
    "        from copy import deepcopy\n",
    "        \n",
    "        if (self.activity == None) | (self.load == None):\n",
    "            self.init_agents()\n",
    "        self._get_dates()\n",
    "        self.config[\"usage\"] = {\n",
    "            \"model_type\": \"logit\",\n",
    "            \"train_start\": deepcopy(self.config[\"data\"][\"start_dates\"][\"usage\"]),\n",
    "        }\n",
    "        for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "            name = (\"usage_\"+ device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "            self.config[name] = self.config[\"usage\"]\n",
    "            self.config[\"data\"][\"start_dates\"][name] = self.config[\"data\"][\"start_dates\"][\"usage\"]\n",
    "            \n",
    "    # extracting the available dates in the data\n",
    "    def get_first_date(self, df):\n",
    "        import pandas as pd\n",
    "\n",
    "        first_data = df.index.to_series()[0]\n",
    "        return (first_data + pd.Timedelta(\"1D\")).replace(hour=0, minute=0, second=0)\n",
    "\n",
    "    def get_last_date(self, df):\n",
    "        import pandas as pd\n",
    "\n",
    "        last_data = df.index.to_series()[-1]\n",
    "        return (last_data - pd.Timedelta(\"1D\")).replace(hour=23, minute=59, second=59)\n",
    "\n",
    "    def get_min_start_date(self, df):\n",
    "        df = df.dropna()\n",
    "        return df.loc[df.index.hour == 0, :].index[0]\n",
    "\n",
    "    def _get_dates(self):\n",
    "        import numpy as np\n",
    "\n",
    "        # first and last date in the data\n",
    "        self.config[\"data\"][\"first_date\"] = str(self.get_first_date(self.preparation.input))[:10]\n",
    "        self.config[\"data\"][\"last_date\"] = str(self.get_last_date(self.preparation.input))[:10]\n",
    "        # start dates\n",
    "        start_dates = {}\n",
    "        for agent, data in self.df.items():\n",
    "            start_dates[agent] = self.get_min_start_date(data)\n",
    "        start_dates[\"combined\"] = np.max(list(start_dates.values()))\n",
    "        self.config[\"data\"][\"start_dates\"] = {\n",
    "            key: str(value)[:10] for key, value in start_dates.items()\n",
    "        }\n",
    "\n",
    "\n",
    "    # running the pipeline\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def pipeline(self, agents, **kwargs):\n",
    "        # converting single agent to list\n",
    "        if type(agents) != list:\n",
    "            agents = [agents]\n",
    " \n",
    "        agents = [agent.lower() for agent in agents]\n",
    "        \n",
    "        if 'preparation' in agents:\n",
    "            self._prepare(**kwargs)\n",
    "        if 'activity' in agents:\n",
    "            self._pipeline_activity_usage_load('activity', **kwargs)\n",
    "        if 'usage' in agents:\n",
    "            usage_agents = [\"usage_\"+ device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower() for device in self.config[\"user_input\"][\"shiftable_devices\"]]\n",
    "            for agent in usage_agents:\n",
    "                self._pipeline_activity_usage_load(agent, **kwargs)\n",
    "        if 'load' in agents:\n",
    "            self._pipeline_activity_usage_load('load', **kwargs)\n",
    "        if 'recommendation' in agents:\n",
    "            self._get_recommendations(**kwargs)\n",
    "            \n",
    "    def init_agents(self):\n",
    "        import agents\n",
    "\n",
    "        # initialize the agents\n",
    "        self.activity = agents.Activity_Agent(self.df[\"activity\"])\n",
    "        self.load = agents.Load_Agent(self.df[\"load\"])\n",
    "\n",
    "        # initialize usage agents for the shiftable devices: agent = usage_name\n",
    "        for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "            name = (\"usage_\"+ device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "            exec(f'self.{name} = Usage_Agent(self.df[\"usage\"], \"{device}\")')\n",
    "            self.df[name] = self.df[\"usage\"]\n",
    "\n",
    "        self.recommendation = agents.Recommendation_Agent(\n",
    "            self.df[\"activity\"],\n",
    "            self.df[\"usage\"],\n",
    "            self.df[\"load\"],\n",
    "            self.price.input,\n",
    "            self.config[\"user_input\"][\"shiftable_devices\"],\n",
    "        )\n",
    "            \n",
    "    def _prepare(self, agent=\"all\"):\n",
    "        lines = {\n",
    "            \"activity\": 'self.df[\"activity\"] = self.preparation.pipeline_activity(self.preparation.input, self.config[\"preparation\"][\"activity\"])',\n",
    "            \"usage\": 'self.df[\"usage\"] = self.preparation.pipeline_usage(self.preparation.input, self.config[\"preparation\"][\"usage\"])',\n",
    "            \"load\": 'self.df[\"load\"] ,_,_ = self.preparation.pipeline_load(self.preparation.input, self.config[\"preparation\"][\"load\"])',\n",
    "        }\n",
    "        if agent == \"all\":\n",
    "            for agent in [\"activity\", \"usage\", \"load\"]:\n",
    "                exec(lines[agent])\n",
    "                print(f\"[evaluation agent] Finished preparing the data for the {agent} agent.\")\n",
    "        else:\n",
    "            exec(lines[agent])\n",
    "            print(f\"[evaluation agent] Finished preparing the data for the {agent} agent.\")\n",
    "\n",
    "    def _pipeline_activity_usage_load(self, agent, verbose=1):\n",
    "        import pandas as pd\n",
    "        from IPython.display import clear_output\n",
    "        import time\n",
    "\n",
    "        self.output[agent] = {}\n",
    "        self.errors[agent] = {}\n",
    "\n",
    "        # init agents\n",
    "        if (self.activity == None) | (self.load == None):\n",
    "            self.init_agents()\n",
    "\n",
    "        # determining the dates\n",
    "        dates = self.df[agent].index.to_series()\n",
    "        start = pd.to_datetime(self.config[\"data\"][\"start_dates\"][agent])\n",
    "        end = pd.to_datetime(self.config[\"data\"][\"last_date\"]).replace(\n",
    "            hour=23, minute=59, second=59\n",
    "        )\n",
    "        dates = dates[(dates >= start) & (dates <= end)].resample(\"1D\").count()\n",
    "        dates = [str(date)[:10] for date in list(dates.index)]\n",
    "\n",
    "        # pipeline funtion\n",
    "        start = time.time() if verbose >= 1 else None\n",
    "        for date in dates:\n",
    "            try:\n",
    "                self.output[agent][date] = eval(f'self.{agent}.pipeline(self.{agent}.input, \"{date}\", **self.config[\"{agent}\"])')\n",
    "                # verbose\n",
    "                if verbose >= 1:\n",
    "                    clear_output(wait=True)\n",
    "                    elapsed = time.time() - start\n",
    "                    remaining = (elapsed / (len(dates)) * (len(dates) - (dates.index(date) + 1)))\n",
    "                    print(f\"agent:\\t\\t{agent}\")\n",
    "                    print(f\"progress: \\t{dates.index(date)+1}/{len(dates)}\")\n",
    "                    print(f\"time:\\t\\t[{self._format_time(elapsed)}<{self._format_time(remaining)}]\\n\")\n",
    "                    print(self.output[agent][date])\n",
    "            except Exception as e:\n",
    "                self.errors[agent][date] = type(e).__name__\n",
    "\n",
    "    def _get_recommendations(\n",
    "        self, activity_threshold, usage_threshold, dates: tuple = \"all\"\n",
    "    ):\n",
    "        import numpy as np\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        # determining dates\n",
    "        start = (\n",
    "            self.config[\"data\"][\"start_dates\"][\"combined\"]\n",
    "            if dates == \"all\"\n",
    "            else dates[0]\n",
    "        )\n",
    "        end = self.config[\"data\"][\"last_date\"] if dates == \"all\" else dates[1]\n",
    "        dates = np.arange(\n",
    "            np.datetime64(start),\n",
    "            np.datetime64(end) + np.timedelta64(1, \"D\"),\n",
    "            np.timedelta64(1, \"D\"),\n",
    "        )\n",
    "        dates = [str(date) for date in dates]\n",
    "\n",
    "        # creating recommendations\n",
    "        self.errors[\"recommendation\"] = {}\n",
    "        self.output[\"recommendation\"] = {}\n",
    "        for date in dates:\n",
    "            try:\n",
    "                self.output[\"recommendation\"][date] = self.recommendation.pipeline(\n",
    "                    date, activity_threshold, usage_threshold, evaluation=self.output\n",
    "                )\n",
    "            except Exception as e:\n",
    "                self.errors[\"recommendation\"][date] = e\n",
    "\n",
    "        # merging the recommendations into one dataframe\n",
    "        df = list(self.output[\"recommendation\"].values())[0]\n",
    "\n",
    "        for idx in range(1, len(self.output[\"recommendation\"].values())):\n",
    "            df = df.append(list(self.output[\"recommendation\"].values())[idx])\n",
    "        df.set_index(\"recommendation_date\", inplace=True)\n",
    "        self.output[\"recommendation\"] = df\n",
    "        clear_output()\n",
    "\n",
    "        \n",
    "    # individual agent scores\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def get_agent_scores(self):\n",
    "        scores = {}\n",
    "        scores['activity_auc'] = None\n",
    "        scores['usage_auc'] = {}\n",
    "        scores['load_mse'] = {}\n",
    "\n",
    "        agents = self._get_agent_names()\n",
    "        for agent in agents:\n",
    "            agent_type = agent.split('_')[0]\n",
    "    \n",
    "            if agent_type == 'activity':\n",
    "                _, auc_test, _ = self[agent].evaluate(self[agent].input, **self.config[agent])\n",
    "                scores['activity_auc'] = auc_test\n",
    "            if agent_type == 'usage':\n",
    "                _, auc_test, _ = self[agent].evaluate(self[agent].input, **self.config[agent])\n",
    "                scores['usage_auc'][self[agent].device] = auc_test\n",
    "            if agent_type == 'load':\n",
    "                try:\n",
    "                    scores['load_mse'] = self.load.evaluate(**self.config['load'], evaluation=self.output['load'])\n",
    "                except KeyError:\n",
    "                    scores['load_mse'] = self.load.evaluate(**self.config['load'])\n",
    "        self.agent_scores = scores\n",
    "        return scores\n",
    "    \n",
    "    def agent_scores_to_summary(self, scores='default'):\n",
    "        import pandas as pd\n",
    "\n",
    "        if scores == 'default':\n",
    "            scores = self.agent_scores\n",
    "\n",
    "        summary = {}\n",
    "        summary['activity_auc'] = pd.DataFrame()\n",
    "        summary['usage_auc'] = pd.DataFrame()\n",
    "        summary['load_mse'] = pd.DataFrame()\n",
    "\n",
    "        household_id = self.config['data']['household']\n",
    "        devices = self.config['user_input']['shiftable_devices']\n",
    "\n",
    "        # activity \n",
    "        summary['activity_auc'].loc[household_id, '-'] = scores['activity_auc']\n",
    "        # usage\n",
    "        i = 0\n",
    "        for device in devices:\n",
    "            summary['usage_auc'].loc[household_id, i] = scores['usage_auc'][device]\n",
    "            i += 1\n",
    "        #load\n",
    "        i = 0\n",
    "        for device in devices:\n",
    "            summary['load_mse'].loc[household_id, i] = scores['load_mse'][device]\n",
    "            i += 1\n",
    "        \n",
    "        summary['activity_auc'].index.name = 'household'\n",
    "        summary['usage_auc'].index.name = 'household'\n",
    "        summary['load_mse'].index.name = 'household'\n",
    "        summary['usage_auc'].columns.name = 'device'\n",
    "        summary['load_mse'].columns.name = 'device'\n",
    "        return summary\n",
    "    \n",
    "    \n",
    "    # cold start: predict on all data\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def predict_all(self, agent, **kwargs):\n",
    "        agent_type = agent.split(\"_\")[0]\n",
    "        return eval(f\"self._predict_all_{agent_type}(agent, **kwargs)\")\n",
    "    \n",
    "    def _predict_all_load(self, agent, device):\n",
    "        y_hat = {\n",
    "            date: profiles.loc[device, :]\n",
    "            for date, profiles in self.output[agent].items()\n",
    "        }\n",
    "        return y_hat\n",
    "    \n",
    "    def _predict_all_activity(self, agent):\n",
    "        return self._predict_all_activity_usage(agent)\n",
    "\n",
    "    def _predict_all_usage(self, agent):\n",
    "        return self._predict_all_activity_usage(agent)\n",
    "\n",
    "    def _predict_all_activity_usage(self, agent):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "        y_hat = {}\n",
    "        # intitializing the error dict\n",
    "        try:\n",
    "            self.errors[\"evaluation\"]\n",
    "        except KeyError:\n",
    "            self.errors[\"evaluation\"] = {}\n",
    "\n",
    "        try:\n",
    "            self.errors[\"evaluation\"][agent]\n",
    "        except KeyError:\n",
    "            self.errors[\"evaluation\"][agent] = {}\n",
    "\n",
    "        # determining the dates\n",
    "        dates = np.arange(\n",
    "            np.datetime64(self.config[\"data\"][\"start_dates\"][agent]),\n",
    "            np.datetime64(self.config[\"data\"][\"last_date\"]) + np.timedelta64(1, \"D\"),\n",
    "            np.timedelta64(1, \"D\"),\n",
    "        )\n",
    "        start = dates[0]\n",
    "        end = dates[-1] + pd.Timedelta(days=1, seconds=-1)\n",
    "\n",
    "        # creating X_test\n",
    "        X_test, _, _, _ = self[agent].train_test_split(\n",
    "            self[agent].input,\n",
    "            dates[-1] + np.timedelta64(1, \"D\"),\n",
    "            train_start=self.config[\"data\"][\"start_dates\"][agent],\n",
    "        )\n",
    "\n",
    "        # creating predictions\n",
    "        for date in dates:\n",
    "            X_train, y_train, _, _ = self[agent].train_test_split(\n",
    "                self[agent].input,\n",
    "                date,\n",
    "                train_start=self.config[\"data\"][\"start_dates\"][agent],\n",
    "            )\n",
    "            try:\n",
    "                model = self[agent].fit(X_train, y_train, \"logit\")\n",
    "                y_hat[date] = self[agent].predict(model, X_test)\n",
    "            except Exception as e:\n",
    "                self.errors[\"evaluation\"][agent][date] = type(e).__name__\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "    # cold start: calculate cold start scores\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def get_cold_start_scores(self, fn: dict = \"default\"):\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        scores = {}\n",
    "        fn = {} if fn == \"default\" else fn\n",
    "        \n",
    "        # activity-agent\n",
    "        scores[\"activity\"] = self._get_cold_start_score(\"activity\", fn=fn.get(\"activity\", \"default\"))\n",
    "        clear_output()\n",
    "\n",
    "        for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "            name = device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "            # usage agent\n",
    "            scores[\"usage_\" + name] = self._get_cold_start_score(\"usage_\" + name, fn=fn.get(\"usage\", \"default\"))\n",
    "            # load agent\n",
    "            scores[\"load_\" + name] = self._get_cold_start_score(\"load\", fn=fn.get(\"load\", \"default\"), device=device)\n",
    "            clear_output()\n",
    "        self.cold_start_scores = scores\n",
    "    \n",
    "    def _get_cold_start_score(self, agent, fn=\"default\", **kwargs):\n",
    "        import sklearn.metrics\n",
    "        import numpy as np\n",
    "\n",
    "        agent_type = agent.split(\"_\")[0]\n",
    "        # specifying the correct score function\n",
    "        fn_dict = {\n",
    "            \"activity\": f\"self.{agent}.auc\",\n",
    "            \"usage\": f\"self.{agent}.auc\",\n",
    "            \"load\": \"sklearn.metrics.mean_squared_error\",\n",
    "        }\n",
    "        fn = eval(fn_dict[agent_type]) if fn == \"default\" else fn\n",
    "\n",
    "        # specifying the correct y_true, y_hat\n",
    "        y_dict = {\n",
    "            \"activity\": \"self[agent].train_test_split(self[agent].input, date=np.datetime64(self.config['data']['last_date'])+np.timedelta64(1, 'D'), train_start=self.config['data']['start_dates'][agent])\",\n",
    "            \"usage\": \"self[agent].train_test_split(self[agent].input, date=np.datetime64(self.config['data']['last_date'])+np.timedelta64(1, 'D'), train_start=self.config['data']['start_dates'][agent])\",\n",
    "            \"load\": \"list(self.output['load'].values())[-1].loc[kwargs['device'], :]\",\n",
    "        }\n",
    "        y_true = eval(y_dict[agent_type])\n",
    "        y_true = y_true if agent_type == \"load\" else y_true[1]\n",
    "        y_hat = self.predict_all(agent, **kwargs)\n",
    "\n",
    "        # calculating the scores\n",
    "        scores = {}\n",
    "        for date, pred in y_hat.items():\n",
    "            scores[date] = fn(y_true, pred)\n",
    "        return scores\n",
    "\n",
    "    def cold_start_scores_to_df(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "        scores_df = pd.DataFrame()\n",
    "        # convert dicts into dataframe\n",
    "        for key in self.cold_start_scores.keys():\n",
    "            for date, score in self.cold_start_scores[key].items():\n",
    "                scores_df.loc[str(date), key] = score\n",
    "\n",
    "        # sort the dataframe\n",
    "        cols = (\n",
    "            [\"activity\"]\n",
    "            + [col for col in scores_df if col.startswith(\"usage\")]\n",
    "            + [col for col in scores_df if col.startswith(\"load\")]\n",
    "        )\n",
    "        scores_df.index = scores_df.index.map(np.datetime64)\n",
    "        scores_df = scores_df[cols].sort_index()\n",
    "        return scores_df\n",
    "    \n",
    "    def get_cold_start_days(self, tolerance_values):\n",
    "        import pandas as pd\n",
    "\n",
    "        self.cold_start_days = pd.DataFrame({\"tolerance\": []}).set_index(\"tolerance\")\n",
    "        scores_df = self.cold_start_scores_to_df()\n",
    "        tolerance_fn = {\n",
    "            \"activity\": \"scores_df[agent].max() * (1 - tolerance[agent_type])\",\n",
    "            \"usage\": \"scores_df[agent].max() * (1 - tolerance[agent_type])\",\n",
    "            \"load\": \"tolerance['load']\",\n",
    "        }\n",
    "\n",
    "        # agent coldstart days\n",
    "        for tolerance in tolerance_values:\n",
    "            tolerance = {\"activity\": tolerance, \"usage\": tolerance, \"load\": tolerance}\n",
    "\n",
    "            for agent in scores_df.columns:\n",
    "                agent_type = agent.split(\"_\")[0]\n",
    "\n",
    "                done = False\n",
    "                day = 0\n",
    "                while not done:\n",
    "                    day += 1\n",
    "                    tolerance_value = eval(tolerance_fn[agent_type])\n",
    "                    if agent_type == \"load\":\n",
    "                        done = all(scores_df[agent].values[day - 1 :] < tolerance_value)\n",
    "                    else:\n",
    "                        done = all(scores_df[agent].values[day - 1 :] > tolerance_value)\n",
    "                self.cold_start_days.loc[tolerance[agent_type], agent] = day\n",
    "        # framework cold start days\n",
    "        self.cold_start_days['framework'] = self.cold_start_days.max(axis=1)\n",
    "    \n",
    "    \n",
    "    def cold_start_to_summary(self, tolerance_values='all'):\n",
    "        import pandas as pd\n",
    "        \n",
    "        if tolerance_values == 'all':\n",
    "            tolerance_values = list(self.cold_start_days.index)\n",
    "        \n",
    "        household_id = self.config['data']['household']\n",
    "        devices = self.config['user_input']['shiftable_devices']\n",
    "\n",
    "        summary = {}\n",
    "        summary['activity'] = {}\n",
    "        summary['usage'] = {}\n",
    "        summary['load'] = {}\n",
    "        summary['framework'] = {}\n",
    "\n",
    "        # activity agent\n",
    "        summary['activity']['-'] = {}  # '-': placeholder for device\n",
    "        summary['activity']['-'][household_id] = self.cold_start_days['activity'][tolerance_values].astype(int).to_list()\n",
    "        # usage agent\n",
    "        i = 0\n",
    "        for device in devices:\n",
    "            name = 'usage_' + device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "            summary['usage'][i] = {}\n",
    "            summary['usage'][i][household_id] = self.cold_start_days[name][tolerance_values].astype(int).to_list()\n",
    "            i += 1\n",
    "\n",
    "        # load agent\n",
    "        i = 0\n",
    "        for device in devices:\n",
    "            name = 'load_' + device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "            summary['load'][i] = {}\n",
    "            summary['load'][i][household_id] = self.cold_start_days[name][tolerance_values].astype(int).to_list()\n",
    "            i += 1\n",
    "    \n",
    "        # framework\n",
    "        summary['framework']['-'] = {}  # '-': placeholder for device\n",
    "        summary['framework']['-'][household_id] = self.cold_start_days['framework'][tolerance_values].astype(int).to_list()\n",
    "\n",
    "        # converting the format\n",
    "        for key, value in summary.items():\n",
    "            summary[key] = pd.DataFrame(value)\n",
    "            summary[key].columns.name = 'device'\n",
    "            summary[key].index.name = 'household'\n",
    "        return summary\n",
    "    \n",
    "    # cold start: visualizations\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def _plot_axs(self, axs, y, x=None, legend=None, **kwargs):\n",
    "        axs.plot(x, y) if x != None else axs.plot(y)\n",
    "        axs.set(**kwargs)\n",
    "        axs.legend(legend) if legend != None else None\n",
    "\n",
    "    def visualize_cold_start(self, metrics_name: dict, tolerance: dict=None, figsize=(18, 5)):\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        scores_df = self.cold_start_scores_to_df()\n",
    "        fig, axs = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "        # activity\n",
    "        self._plot_axs(\n",
    "            axs[0],\n",
    "            x=range(1, scores_df.shape[0] + 1),\n",
    "            y=scores_df[\"activity\"],\n",
    "            title=f\"[activity] {metrics_name['activity']}\",\n",
    "        )\n",
    "        legend = ['activity']\n",
    "        if tolerance != None: \n",
    "            tolerance_value = scores_df[\"activity\"].max() * (1 - tolerance[\"activity\"])\n",
    "            color = axs[0].lines[-1].get_color()\n",
    "            axs[0].plot([tolerance_value] * scores_df.shape[0], \"--\", c=color)\n",
    "            legend.append([f\"tolerance@{tolerance['activity']}\"])\n",
    "        axs[0].legend(legend)\n",
    "        axs[0].set_xlabel(\"days\")\n",
    "\n",
    "        # usage\n",
    "        usage_agents = [agent for agent in scores_df.columns if agent.find(\"usage\") != -1]\n",
    "        legend = []\n",
    "        for agent in usage_agents:\n",
    "            self._plot_axs(axs[1],\n",
    "                x=range(1, scores_df.shape[0] + 1),\n",
    "                y=scores_df[agent],\n",
    "                title=f\"[usage] {metrics_name['usage']}\",\n",
    "            )\n",
    "            legend += [agent]\n",
    "            if tolerance != None:\n",
    "                tolerance_value = scores_df[agent].max() * (1 - tolerance[\"usage\"])\n",
    "                color = axs[1].lines[-1].get_color()\n",
    "                axs[1].plot([tolerance_value] * scores_df.shape[0], \"--\", c=color)\n",
    "                legend += [f\"tolerance_{agent.replace('usage_', '')}@{tolerance['usage']}\"]\n",
    "        axs[1].legend(legend)\n",
    "        axs[1].set_xlabel(\"days\")\n",
    "\n",
    "        # load\n",
    "        load_agents = [agent for agent in scores_df.columns if agent.find(\"load\") != -1]\n",
    "        legend = []\n",
    "        for agent in load_agents:\n",
    "            self._plot_axs(\n",
    "                axs[2],\n",
    "                x=range(1, scores_df.shape[0] + 1),\n",
    "                y=scores_df[agent],\n",
    "                title=f\"[load] {metrics_name['load']}\",\n",
    "            )\n",
    "            legend += [agent]\n",
    "        if tolerance != None:\n",
    "            axs[2].plot([tolerance[\"load\"]] * scores_df.shape[0], \"--\", c=\"black\")\n",
    "            legend += [f\"tolerance@{tolerance['load']}\"]\n",
    "        axs[2].legend(legend)\n",
    "        axs[2].set_xlabel(\"days\")\n",
    "\n",
    "    \n",
    "    # evaluation: calculate costs per device run\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def calculate_cost(self, date, hour, load):\n",
    "        import numpy as np\n",
    "\n",
    "        if np.isnan(hour):\n",
    "            return np.nan\n",
    "        else:\n",
    "            price_idx = self.price.input.index.values\n",
    "            prices = self.price.input.values\n",
    "\n",
    "            dt = np.datetime64(date) + np.timedelta64(int(hour), \"h\")\n",
    "            # getting the correct position for the load in the load array\n",
    "            i = np.where(price_idx == dt)[0][0]\n",
    "\n",
    "            # reshaping the load array and calculating the costs\n",
    "            before = np.zeros(i)\n",
    "            after = np.zeros(prices.shape[0] - load.shape[0] - before.shape[0])\n",
    "            load = np.hstack([before, load, after])\n",
    "            return np.dot(load, prices)\n",
    "\n",
    "    def _get_usage(self, device, date):\n",
    "        return self.df[\"usage\"].loc[date, device + \"_usage\"]\n",
    "\n",
    "    def _get_activity(self, date, hour):\n",
    "        import numpy as np\n",
    "\n",
    "        if np.isnan(hour):\n",
    "            return np.nan\n",
    "        else:\n",
    "            dt = np.datetime64(date) + np.timedelta64(int(hour), \"h\")\n",
    "            return self.activity.input.loc[dt, \"activity\"]\n",
    "\n",
    "    def _get_starting_times(self, device):\n",
    "        import numpy as np\n",
    "\n",
    "        # extracts hours in which the device is turned on,\n",
    "        # conditional on that the device was turned off the hour before\n",
    "        times = self.df[\"load\"][device].index.to_numpy()\n",
    "        hour = self.df[\"load\"][device].values\n",
    "        before = np.insert(hour, 0, 0)[:-1]\n",
    "        return times[(before == 0) & (hour != 0)]\n",
    "\n",
    "    def _get_starting_hours(self, device, date):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "\n",
    "        times = self._get_starting_times(device)\n",
    "        date = np.datetime64(date) if type(date) != np.datetime64 else date\n",
    "        times = times[(times >= date) & (times < date + np.timedelta64(1, \"D\"))]\n",
    "        hours = (\n",
    "            pd.Series(times).apply(lambda x: x.hour).to_numpy()\n",
    "            if times.shape[0] != 0\n",
    "            else np.nan\n",
    "        )\n",
    "        return hours\n",
    "\n",
    "    def _get_load(self, true_loads, device, date, hour):\n",
    "        import numpy as np\n",
    "\n",
    "        try:\n",
    "            dt = np.datetime64(date) + np.timedelta64(hour, \"h\")\n",
    "        # if hour == NaN, return zero load profile\n",
    "        except ValueError:\n",
    "            return np.zeros(24)\n",
    "        try:\n",
    "            return true_loads[device].loc[dt].values\n",
    "        except KeyError as ke:\n",
    "            # return a zero load profile if the datetime index was not found\n",
    "            if str(ke).split(\"(\")[0] == \"numpy.datetime64\":\n",
    "                return np.zeros(24)\n",
    "            # in any other case raise the key error\n",
    "            else:\n",
    "                raise ke\n",
    "\n",
    "\n",
    "    # evaluation: performance metrics\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def evaluate(self, activity_threshold, usage_threshold):\n",
    "        name = f\"activity: {activity_threshold}; usage: {usage_threshold}\"\n",
    "        #self._get_recommendations(activity_threshold, usage_threshold)\n",
    "        self.pipeline('recommendation', activity_threshold=activity_threshold, usage_threshold=usage_threshold, dates='all')\n",
    "        self.results[name] = self._evaluate()\n",
    "\n",
    "    def _evaluate(self):\n",
    "        import numpy as np\n",
    "\n",
    "        df = self.output[\"recommendation\"].copy()\n",
    "        \n",
    "        # usage and activity target\n",
    "        df[\"usage_true\"] = df.apply(lambda row: self._get_usage(row[\"device\"], row.name), axis=1)\n",
    "        df[\"activity_true\"] = df.apply(lambda row: self._get_activity(row.name, row[\"recommendation\"]), axis=1)\n",
    "        df[\"acceptable\"] = df[\"usage_true\"] * df[\"activity_true\"]\n",
    "\n",
    "        # starting times\n",
    "        df[\"starting_times\"] = df.apply(\n",
    "            lambda row: self._get_starting_hours(row[\"device\"], row.name), axis=1\n",
    "        )\n",
    "        df[\"relevant_start\"] = abs(df[\"starting_times\"] - df[\"recommendation\"])\n",
    "        df.loc[df[\"starting_times\"].notna(), \"relevant_start\"] = df[\n",
    "            df[\"starting_times\"].notna()\n",
    "        ].apply(\n",
    "            lambda row: row[\"starting_times\"][np.argmin(row[\"relevant_start\"])], axis=1\n",
    "        )\n",
    "\n",
    "        # actual loads\n",
    "        true_loads = self.load.get_true_loads(self.config[\"user_input\"][\"shiftable_devices\"])\n",
    "        df[\"load\"] = df.apply(lambda row: self._get_load(true_loads, row[\"device\"], row.name, row[\"relevant_start\"]), axis=1)\n",
    "\n",
    "        # calculating costs\n",
    "        df[\"cost_no_recommendation\"] = df.apply(lambda row: self.calculate_cost(row.name, row[\"relevant_start\"], row[\"load\"]), axis=1)\n",
    "        df[\"cost_recommendation\"] = df.apply(lambda row: self.calculate_cost(row.name, row[\"recommendation\"], row[\"load\"]),axis=1)\n",
    "        df[\"savings\"] = df[\"cost_no_recommendation\"] - df[\"cost_recommendation\"]\n",
    "        df[\"relative_savings\"] = df[\"savings\"] / df[\"cost_no_recommendation\"]\n",
    "\n",
    "        return df[\n",
    "            [\n",
    "                \"device\",\n",
    "                \"recommendation\",\n",
    "                \"acceptable\",\n",
    "                \"relevant_start\",\n",
    "                \"cost_no_recommendation\",\n",
    "                \"cost_recommendation\",\n",
    "                \"savings\",\n",
    "                \"relative_savings\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    def _result_to_summary(self, result):\n",
    "        return {\n",
    "            \"n_recommendations\": result[\"recommendation\"].count(),\n",
    "            \"acceptable\": result[\"acceptable\"].mean(),\n",
    "            \"total_savings\": (result[\"acceptable\"] * result[\"savings\"]).sum(),\n",
    "            \"relative_savings_mean\": result[\"relative_savings\"].mean(),\n",
    "            \"relative_savings_median\": result[\"relative_savings\"].median(),\n",
    "        }\n",
    "\n",
    "    def results_to_summary(self):\n",
    "        import pandas as pd\n",
    "\n",
    "        summary = {\n",
    "            name: self._result_to_summary(result)\n",
    "            for name, result in self.results.items()\n",
    "        }\n",
    "        return pd.DataFrame.from_dict(summary, orient=\"index\")\n",
    "    \n",
    "\n",
    "    # evaluation: grid search and sensitivity\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def grid_search(self, activity_thresholds, usage_thresholds):\n",
    "        import itertools\n",
    "        from tqdm import tqdm\n",
    "        \n",
    "        # updating the config \n",
    "        try:\n",
    "            self.config['evaluation']\n",
    "        except:\n",
    "            self.config['evaluation'] = {}\n",
    "        \n",
    "        self.config['evaluation']['grid_search'] = {}\n",
    "        self.config['evaluation']['grid_search']['activity_thresholds'] = list(activity_thresholds)\n",
    "        self.config['evaluation']['grid_search']['usage_thresholds'] = list(usage_thresholds)\n",
    "        \n",
    "        # testing candidate thresholds\n",
    "        iterator = itertools.product(activity_thresholds, usage_thresholds)\n",
    "        for thresholds in tqdm(list(iterator)):\n",
    "            self.evaluate(thresholds[0], thresholds[1])\n",
    "\n",
    "    def get_sensitivity(self, target):\n",
    "        import pandas as pd\n",
    "\n",
    "        df = self.results_to_summary()\n",
    "        sensitivity = pd.DataFrame()\n",
    "        for threshold_name in df.index:\n",
    "            thresholds = threshold_name.split(\"; \")\n",
    "            activity_threshold, usage_threshold = [th.split(\": \")[1] for th in thresholds]\n",
    "            sensitivity.loc[activity_threshold, usage_threshold] = df.loc[threshold_name, target]\n",
    "        # sort and name rows and columns\n",
    "        sensitivity = sensitivity.loc[sorted(sensitivity.index), :]\n",
    "        sensitivity = sensitivity.loc[:, sorted(sensitivity.columns)]\n",
    "        sensitivity.index.name = \"activity_threshold\"\n",
    "        sensitivity.columns.name = \"usage_threshold\"\n",
    "        return sensitivity\n",
    "    \n",
    "    def get_optimal_thresholds(self):\n",
    "        df = self.results_to_summary()\n",
    "        result = df.sort_values(by='total_savings').iloc[-1, :]\n",
    "        thresholds = result.name.split('; ')\n",
    "        thresholds = [threshold.split(': ') for threshold in thresholds]\n",
    "        thresholds = {f\"{threshold}_threshold\": value for threshold, value in thresholds}\n",
    "        self.config['evaluation']['grid_search']['optimal_thresholds'] = thresholds\n",
    "        return thresholds\n",
    "        \n",
    "    def thresholds_to_index(self, activity_threshold='optimal', usage_threshold='optimal'):\n",
    "        if activity_threshold == 'optimal':\n",
    "            activity_threshold = self.config['evaluation']['grid_search']['optimal_thresholds']['activity_threshold']\n",
    "        if usage_threshold == 'optimal':\n",
    "            usage_threshold = self.config['evaluation']['grid_search']['optimal_thresholds']['usage_threshold']\n",
    "        return f\"activity: {activity_threshold}; usage: {usage_threshold}\"\n",
    "    \n",
    "    def optimal_result_to_summary(self):\n",
    "        import pandas as pd\n",
    "        optimal_thresholds = self.get_optimal_thresholds()\n",
    "        optimal_thresholds_index = self.thresholds_to_index()\n",
    "        result = self.results_to_summary().loc[optimal_thresholds_index,:]\n",
    "        result = result.append(pd.Series(optimal_thresholds))\n",
    "        result.name = self.config['data']['household']\n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "name": "conda-env-xai_energy_efficient_smart_home-py",
   "language": "python",
   "display_name": "Python [conda env:xai_energy_efficient_smart_home] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}