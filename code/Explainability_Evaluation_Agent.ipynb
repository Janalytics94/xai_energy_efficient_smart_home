{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Performance Evaluation Agent**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To evaluate the performance of our recommender system, we will analyze the system regarding the individual agents’ performance, the cold start problem, the sensitivity to changes in the recommendation hyperparameter and potential energy cost savings. We will introduce a further agent called Evaluation Agent which will perform all evaluation actions.\n",
    "\n",
    "We will perform our evaluation analysis for households 1 to 10 in the REFIT: Electrical Load Measurements data (Murray et at., 2019), to validate our evaluation results.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **1. Preparing the Environment**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from agents import Performance_Evaluation_Agent\n",
    "from helper_functions import Helper\n",
    "\n",
    "helper = Helper()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "import scipy.spatial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "EXPORT_PATH = '../export/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "## **2. Preparations for Evaluating the Performance of our Recommender System**\n",
    "### **2.1 Determining User Input**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we are able to use our recommender system and evaluate its performance, we need to specify the required user inputs (i.e. active appliances, shiftable devices and the consumption threshold). For specifying which of the devices in the respective household will be determined as active appliances and shiftable devices, we look at the description of the devices provided in the readme file and categorize the devices according to our definitions of the categories. Furthermore, we validate that the used devices do not contain any noise in their consumption data and remove devices which contain noise, i.e. consume energy constantly over time. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "readme = DATA_PATH+'REFIT_Readme.txt'\n",
    "readme = helper.load_txt(readme)\n",
    "start = readme.rfind('House 1\\n')\n",
    "end = readme.find('House 11\\n')\n",
    "print(readme[start:end])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "**Shiftable Devices**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# manual input, determined using information provided in the readme\n",
    "# validated in the next step using the validate thresholds functionality\n",
    "shiftable_devices = {\n",
    "    1: ['Tumble Dryer', 'Washing Machine', 'Dishwasher'],\n",
    "    2: ['Washing Machine', 'Dishwasher'],\n",
    "    3: ['Tumble Dryer', 'Washing Machine', 'Dishwasher'],\n",
    "    4: ['Washing Machine (1)', 'Washing Machine (2)'],\n",
    "    5: ['Tumble Dryer'], # , 'Washing Machine' --> consumes energy constantly; , 'Dishwasher' --> noise at 3am\n",
    "    6: ['Washing Machine', 'Dishwasher'],\n",
    "    7: ['Tumble Dryer', 'Washing Machine', 'Dishwasher'],\n",
    "    8: ['Washing Machine'], # 'Dryer' --> consumes constantly\n",
    "    9: ['Washer Dryer', 'Washing Machine', 'Dishwasher'], \n",
    "    10: ['Washing Machine'] #'Dishwasher'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "**Active Appliances**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# manual input, determined using information provided in the readme\n",
    "# validated in the next step using the validate thresholds functionality\n",
    "active_appliances = {\n",
    "    1: deepcopy(shiftable_devices[1]) + ['Television Site', 'Computer Site'],\n",
    "    2: deepcopy(shiftable_devices[2]) + ['Television', 'Microwave', 'Toaster', 'Hi-Fi', 'Kettle'],\n",
    "    3: deepcopy(shiftable_devices[3]) + ['Toaster', 'Television', 'Microwave', 'Kettle'],\n",
    "    4: deepcopy(shiftable_devices[4]) + ['Television Site', 'Kettle'], #'Microwave', 'Computer Site' --> consume energy constantly \n",
    "    5: deepcopy(shiftable_devices[5]) + ['Television Site', 'Combination Microwave', 'Kettle', 'Toaster'], # 'Computer Site', --> consumes energy constantly\n",
    "    6: deepcopy(shiftable_devices[6]) + ['MJY Computer', 'Kettle', 'Toaster'], #, 'PGM Computer', 'Television Site' 'Microwave' --> consume energy constantly \n",
    "    7: deepcopy(shiftable_devices[7]) + ['Television Site', 'Toaster', 'Kettle'],\n",
    "    8: deepcopy(shiftable_devices[8]) + ['Toaster', 'Kettle'], # 'Television Site', 'Computer' --> consume energy constantly\n",
    "    9: deepcopy(shiftable_devices[9]) + ['Microwave', 'Kettle'], #'Television Site', 'Hi-Fi' --> consume energy constantly\n",
    "    10: deepcopy(shiftable_devices[10]) + ['Magimix (Blender)', 'Microwave'] # 'Television Site' --> consume energy constantly\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "**Energy Consumption Threshold**\n",
    "\n",
    "Our Preparation Agent will require the energy consumption threshold, which will determine if a device was used in a given period. This threshold will allow to reduce the impact of noise in the data. We will determine the optimal thresholds for the households using the Preparation Agent’s validate thresholds method. To demonstrate how noise in the consumption data occurs, we call the validate thresholds method for household 1. The consumption data regarding the Television Site in household 1 seems to contain daily noise around 3 am. We will choose the optimal threshold, such that the noise is removed from the data.\n",
    "\n",
    "Furthermore, we will create our initial evaluation configuration file for each household which will contain the specified user input."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# validating the thresholds for household 1 to show noise in the data\n",
    "household_id = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating the config including the user input\n",
    "config =  {'data': {'household': deepcopy(household_id)}}\n",
    "config['user_input'] = {\n",
    "    'shiftable_devices': deepcopy(shiftable_devices[config['data']['household']]),\n",
    "    'active_appliances': deepcopy(active_appliances[config['data']['household']])\n",
    "}\n",
    "\n",
    "# initializing the evaluation agent\n",
    "model_type = \"logit\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation = Performance_Evaluation_Agent(DATA_PATH, model_type, config, load_data=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preparation = evaluation.preparation\n",
    "\n",
    "# Data-Preparation\n",
    "df_th = preparation.truncate(preparation.input)\n",
    "df_th = preparation.scale(df_th)\n",
    "df_th = helper.aggregate(df_th, '60T')\n",
    "\n",
    "# Graphical analysis of candidate thresholds\n",
    "#thresholds = [0] + list(np.geomspace(.01, .4, 5))\n",
    "#preparation.validate_thresholds(df_th, thresholds, config['user_input']['active_appliances'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    1: 0.15,\n",
    "    2: 0.01,\n",
    "    3: 0.01, \n",
    "    4: 0.01, \n",
    "    5: 0.025,\n",
    "    6: 0.065, \n",
    "    7: 0.01, \n",
    "    8: 0.01, # washing machine over night\n",
    "    9: 0.01, \n",
    "    10: 0.01\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### **2.2 Running our Pipeline**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we are able to analyze the performance of our recommender system, we need to calculate all outputs of all our agents and all recommendations possible based on the available data. To conveniently compute these outputs and recommendations for the households, we added a pipeline method to the Evaluation Agent which allows to run every agent of our recommender system for every available date iteratively. We will demonstrate its functionality by creating the recommendations for household 3. \n",
    "\n",
    "Additionally, we will use a further method of the Evaluation Agent to receive the default configuration for evaluating our recommender system."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating the config including the user input\n",
    "config =  {'data': {'household': deepcopy(household_id)}}\n",
    "config['user_input'] = {\n",
    "    'shiftable_devices': deepcopy(shiftable_devices[config['data']['household']]),\n",
    "    'active_appliances': deepcopy(active_appliances[config['data']['household']]),\n",
    "    'threshold': deepcopy(thresholds[config['data']['household']])\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "**Preparing the data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calling the evaluation agent\n",
    "evaluation = Performance_Evaluation_Agent(DATA_PATH, model_type, config)\n",
    "evaluation.get_default_config('preparation')\n",
    "evaluation.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation.pipeline('preparation')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "**Creating all recommendations**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation.get_default_config(['activity', 'usage', 'load'])\n",
    "evaluation.config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md Get all predictions for activity agent for one household\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity_predictions, model = evaluation._pipeline_activity_usage_load(\"activity\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#this takes the prediction out of nesting and puts it into own row\n",
    "activity_predictions_test = activity_predictions.explode('Prediction')\n",
    "activity_predictions_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# just to create time (other way?)\n",
    "row = 1\n",
    "hour = 0\n",
    "hours = []\n",
    "while row <=len(activity_predictions_test):\n",
    "    hours.append(hour)\n",
    "    hour += 1\n",
    "    row += 1\n",
    "    if hour == 24:\n",
    "        hour = 0\n",
    "\n",
    "print(hours)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity_predictions_test['time'] = hours\n",
    "activity_predictions_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity_treshold = config['preparation']['activity']['activity']['threshold']\n",
    "active_predictions = activity_predictions_test[activity_predictions_test.Prediction > activity_treshold]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get data for prediction with Lime and Shap."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load household data for Household 1\n",
    "household = helper.load_household(DATA_PATH, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "threshold = 0.01\n",
    "active_appliances = ['Tumble Dryer', 'Dishwasher', 'Washing Machine','Television', 'Microwave', 'Kettle']\n",
    "shiftable_devices = ['Tumble Dryer', 'Washing Machine', 'Dishwasher']\n",
    "#model_types = ['logit', 'knn', 'ada', 'random forest']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#activity params\n",
    "truncation_params = {\n",
    "    'features': 'all',\n",
    "    'factor': 1.5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "scale_params = {\n",
    "    'features': 'all',\n",
    "    'kind': 'MinMax',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "aggregate_params = {\n",
    "    'resample_param': '60T'\n",
    "}\n",
    "\n",
    "activity_params = {\n",
    "    'active_appliances': active_appliances,\n",
    "    'threshold': threshold\n",
    "}\n",
    "\n",
    "time_params = {\n",
    "    'features': ['hour', 'day_name']\n",
    "}\n",
    "\n",
    "activity_lag_params = {\n",
    "    'features': ['activity'],\n",
    "    'lags': [24, 48, 72]\n",
    "}\n",
    "\n",
    "activity_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'aggregate': aggregate_params,\n",
    "    'activity': activity_params,\n",
    "    'time': time_params,\n",
    "    'activity_lag': activity_lag_params\n",
    "}\n",
    "\n",
    "#load agent\n",
    "device_params = {\n",
    "    'threshold': threshold\n",
    "}\n",
    "\n",
    "load_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'aggregate': aggregate_params,\n",
    "    'shiftable_devices': shiftable_devices,\n",
    "    'device': device_params\n",
    "}\n",
    "\n",
    "#usage agent\n",
    "\n",
    "device = {\n",
    "    'threshold' : threshold}\n",
    "\n",
    "aggregate_params24_H = {\n",
    "    'resample_param': '24H'\n",
    "}\n",
    "\n",
    "usage_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'activity': activity_params,\n",
    "    'aggregate_hour': aggregate_params,\n",
    "    'aggregate_day': aggregate_params24_H,\n",
    "    'time': time_params,\n",
    "    'activity_lag': activity_lag_params,\n",
    "    'shiftable_devices' : shiftable_devices,\n",
    "    'device': device\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from agents import Activity_Agent, Usage_Agent, Load_Agent, Price_Agent, Preparation_Agent\n",
    "#get out X_train etc.\n",
    "# Load pickle data\n",
    "#activity_df = pd.read_pickle('../data/processed_pickle/activity_df.pkl')\n",
    "prep = Preparation_Agent(household)\n",
    "activity_df = prep.pipeline_activity(household, activity_pipe_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity = Activity_Agent(activity_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date = '2016-07-09'\n",
    "X_train, y_train, X_test, y_test = activity.train_test_split(activity_df, date)\n",
    "activity_df.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation Lime, Shap"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictive_models = [model]\n",
    "predictive_models\n",
    "#y_test.head(20)#.iloc[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#14752\n",
    "activity_predictions_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "activity_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'activity_predictions_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-55cc5ed0442d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mactivity_predictions_test\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'activity_predictions_test' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=0)\n",
      "LogisticRegression(random_state=0)\n",
      "LogisticRegression(random_state=0)\n",
      "Unknown model\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-79-4bb9166e93f9>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     42\u001B[0m                                                   categorical_features = [0])\n\u001B[0;32m     43\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m         exp = explainer.explain_instance(data_row = X_test.iloc[local], #changed to somewhere where activity= 1\n\u001B[0m\u001B[0;32m     45\u001B[0m                                     predict_fn = pred_model.predict)\n\u001B[0;32m     46\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    893\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    894\u001B[0m             \u001B[0mmaybe_callable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_if_callable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 895\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmaybe_callable\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    896\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    897\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_is_scalar_access\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1499\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1500\u001B[0m             \u001B[1;31m# validate the location\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1501\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1502\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1503\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_ixs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\xai_energy_efficient_smart_home\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36m_validate_integer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1442\u001B[0m         \u001B[0mlen_axis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1443\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[0mlen_axis\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0mlen_axis\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1444\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mIndexError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"single positional indexer is out-of-bounds\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1445\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1446\u001B[0m     \u001B[1;31m# -------------------------------------------------------------------\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "### LIME Function\n",
    "from lime import lime_tabular\n",
    "import statistics\n",
    "\n",
    "local = 9 #the instance we want to explain\n",
    "n_iter = 1\n",
    "i = 0\n",
    "\n",
    "data = {'Explainability Model': [],\n",
    "        'Predictive Model': [],\n",
    "        'Classifier': [],\n",
    "        'Run Duration': [],\n",
    "        'MAEE': [],\n",
    "        'MSEE': []}\n",
    "exp_eval_df = pd.DataFrame(data)\n",
    "\n",
    "for local in range(0, len(activity_predictions)):\n",
    "    for pred_model in predictive_models:\n",
    "        classifier = pred_model\n",
    "        print(classifier)\n",
    "\n",
    "        print(pred_model)\n",
    "        print(str(pred_model))\n",
    "\n",
    "        if \"KNeighbors\" in str(pred_model):\n",
    "            predictive_model = \"KNN\"\n",
    "        elif \"Random\" in str(pred_model):\n",
    "            predictive_model = \"Random Forest\"\n",
    "        elif \"Ada\" in str(pred_model):\n",
    "            predictive_model = \"AdaBoost\"\n",
    "        else:\n",
    "            predictive_model = \"Unknown model\"\n",
    "\n",
    "        print(predictive_model)\n",
    "\n",
    "        # LIME\n",
    "        explainability_model = 'LIME'\n",
    "        start_time = time.time()\n",
    "        #run once\n",
    "        explainer = lime_tabular.LimeTabularExplainer(training_data = np.array(X_train),\n",
    "                                                  mode = \"regression\",\n",
    "                                                  feature_names = X_train.columns,\n",
    "                                                  categorical_features = [0])\n",
    "\n",
    "        exp = explainer.explain_instance(data_row = X_test.iloc[local], #changed to somewhere where activity= 1\n",
    "                                    predict_fn = pred_model.predict)\n",
    "\n",
    "        exp.show_in_notebook(show_table = True)\n",
    "        end_time = time.time()\n",
    "        difference_time = end_time - start_time\n",
    "\n",
    "        #compute MSEE:\n",
    "        y_expl_i = exp.local_pred\n",
    "        #print(y_expl_i)\n",
    "        #SEE = (y_pred_i - y_expl_i)**2 #squared prediction error for this computation (repetition necessary for MSEE)\n",
    "\n",
    "        rep = 0\n",
    "\n",
    "        exp_list_abs = []\n",
    "        exp_list_squ = []\n",
    "        for rep in range(n_iter): #number of iterations for computing the diffferent lime models\n",
    "\n",
    "            exp = explainer.explain_instance(data_row = X_test.iloc[local], #changed to somewhere where activity= 1\n",
    "                                    predict_fn = pred_model.predict)\n",
    "            exp_list_abs.append(y_pred_i-exp.local_pred)\n",
    "            exp_list_squ.append((y_pred_i-exp.local_pred)**2)\n",
    "\n",
    "        exp_np_abs =np.array(exp_list_abs)\n",
    "        exp_np_squ =np.array(exp_list_squ)\n",
    "        #exp_list_abs.to_numpy()\n",
    "        #exp_list_abs.flatten()\n",
    "        #print(exp_list_abs.flatten())\n",
    "\n",
    "        MAEE = statistics.mean(exp_np_abs.flatten())\n",
    "        MSEE = statistics.mean(exp_np_squ.flatten())\n",
    "        print(MAEE)\n",
    "\n",
    "        #MSEE = mean(exp_list_squ[0])\n",
    "        #print(MSEE)\n",
    "\n",
    "        #exp.as_list()\n",
    "        exp_eval_df.loc[i+1] = [explainability_model, predictive_model, classifier, difference_time, MAEE, MSEE]\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "        # SHAP\n",
    "\n",
    "        explainability_model = 'SHAP'\n",
    "        start_time = time.time()\n",
    "\n",
    "        explainer = shap.KernelExplainer(pred_model.predict_proba, X_train)\n",
    "        shap_values = explainer.shap_values(X_test.iloc[local,:])\n",
    "        display(shap.force_plot(explainer.expected_value[1], shap_values[1], X_test.iloc[local,:]))\n",
    "\n",
    "        end_time = time.time()\n",
    "        difference_time = end_time - start_time\n",
    "\n",
    "        #compute MSEE:\n",
    "        rep = 0\n",
    "\n",
    "        shap_list_abs = []\n",
    "        shap_list_squ = []\n",
    "\n",
    "        for rep in range(n_iter):\n",
    "            explainer = shap.KernelExplainer(pred_model.predict_proba, X_train)\n",
    "            shap_values = explainer.shap_values(X_test.iloc[local,:])\n",
    "            print(shap_values)\n",
    "            # first array = contribution to class 0\n",
    "            # second array = contribution to class 1\n",
    "            contribution_to_class_1 = np.array(shap_values).sum(axis=1)[1] # the red part of the diagram\n",
    "            print(contribution_to_class_1)\n",
    "            base_value = explainer.expected_value[1] # the mean prediction\n",
    "            print(base_value)\n",
    "            y_expl_i = base_value + contribution_to_class_1\n",
    "            print(y_expl_i)\n",
    "            SEE = (y_pred_i[0] - y_expl_i)**2 #squared prediction error for this computation (repetition necessary for MSEE)\n",
    "\n",
    "            shap_list_abs.append(y_pred_i-y_expl_i)\n",
    "            shap_list_squ.append((y_pred_i-y_expl_i)**2)\n",
    "\n",
    "            print(shap_list_abs)\n",
    "\n",
    "        shap_np_abs =np.array(shap_list_abs)\n",
    "        shap_np_squ =np.array(shap_list_squ)\n",
    "\n",
    "        MAEE = statistics.mean(shap_np_abs.flatten())\n",
    "        MSEE = statistics.mean(shap_np_squ.flatten())\n",
    "        print(MAEE)\n",
    "\n",
    "        exp_eval_df.loc[i+1] = [explainability_model, predictive_model, classifier, difference_time, MAEE, MSEE]\n",
    "\n",
    "        i = i+1\n",
    "\n",
    "        print(exp_eval_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_eval_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}