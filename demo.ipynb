{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0071f8e175e610456ffef36eadb93170812a404d84379bd5715daa9aecae9ca07",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "written by: \n",
    "\n",
    "\n",
    "# Explainable Recommendation Systems in Energy‐Efficient Smart Home\n",
    "\n",
    "- **Table of Contents:**\n",
    "\n",
    "    1. Abstract\n",
    "    2. Introduction\n",
    "    3. Literature Review\n",
    "\n",
    "            3.1 Explainable AI (XAI)\n",
    "            3.2 Recommender Systems in SH\n",
    "            3.3. Explainability in RS (one of the cores of this work)\n",
    "\n",
    "    4. Methodology\n",
    "    \n",
    "            4.1 Recommender System \n",
    "            4.2 Algorithms\n",
    "                4.2.1 Model-intrinsic\n",
    "                4.2.2 Model-agnostic\n",
    "            4.3 Evaluation\n",
    "                4.3.1 Performance\n",
    "                4.3.2 Explainability\n",
    "\n",
    "    5. Results\n",
    "\n",
    "            5.1 Recommender System Results\n",
    "            5.2 Our Performance\n",
    "            5.3 Our Explainability\n",
    "\n",
    "    6. Discussion\n",
    "    \n",
    "            6.1. Contributions\n",
    "            6.2. Limitations\n",
    "            6.3. Implications\n",
    "            6.4. Recommendations\n",
    "            6.5. Future Research\n",
    "            \n",
    "    7. Conclusions\n",
    "\n",
    "    References\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Introduction & Motivation\n",
    "The term *Smart Home* refers to technical systems in living spaces and houses which focus on increasing the quality of living, security and efficient energy use (Kolb, 2015). Those systems are usually based on *recommender systems* (RS)  supported by artifical intelligence, which promote energy-saving behaviour and reducing carbon emissions by supporting users in changing their habits. As the human-computer interaction in this context plays a crucial role in the success of these systems it is of utmost importance to avoid any confusion or discomfort (Zhang et. al, 2020). To achieve those goals the user has to understand *why* the system is proposing those recommendations, which is addressed by explainability.\n",
    "The detection of certain habits by the RS allows for load shifting, i.e. the reallocation of an energy-demanding action to another time with less energy demand, which leads to a more efficient consumption of power (Germaine et. al, 2021). In the future, this will become more important as renewable energy sources cannot supply electricity on-demand  (Himeur et. al, 2021). Therefore, adapting the consumption pattern of households could be a viable way to mend that problem without cutting too much into the comfort of consumers.\n",
    "\n",
    "# Methodology / Literature Review\n",
    "\n",
    "An overview over explainability in smart home RS is yet to be published. Zhang & Chen (2020) review explainability in the general RS context. They classify into model-intrinsic and model-agnostic explainability: while the first offers explainability by the nature of the model, in the second case a “black-box” is explained after the application. One mentioned approach in the general machine learning area is local interpretable model-agnostic explanation (LIME) by Ribeiro et al. (2016), that approximates the results of a model with an interpretable, simple model. Most other approaches are not applicable, because of missing data structures in the smart home research. \n",
    "Sardianos et al. (2020) shortly review previous efforts in explainability for recommendation systems for energy efficiency. They point out a knowledge gap in this area that is rarely addressed. They refer to Grimaldo & Novak (2019), who use model-agnostic explainability by incorporating kNNs and decision trees to visualize the relationship of consumption patterns and recommendations. Zhang et al. (2016) apply kNNs to forecast consumption patterns, but do not take into account the explainability of the proposed model.\n",
    "\n",
    "# Knowledge gap \n",
    "\n",
    "Generally, the deployment of RS in the context of energy efficiency has been examined in the recent past. However, as we have elaborated, explainability was only sparsely applied for our given context. In contrast to the existing research we however focus on demand reallocation and not reduction so the goal of the RS is very different and therefore also the recommendations differ greatly. Additionally, our model at the moment is expected to only account for data from smart plugs and not sensors.\n",
    "We will further build on the research of Sardianos et. al (2021) regarding incentives outside of monetary savings and hope to apply their insights to the related field of demand shifting. Further, we will examine existing XAI approaches and their applicability in our given context and if need arises find a novel way to include explainability.\n",
    "\n",
    "# Our research questions\n",
    "\n",
    "To address this problem correctly it has to become transparent why a RS in a smart home environment proposes the next action to a user. This includes transparency of the data set in use, the machine learning model itself and information retrieval or data mining.\n",
    "In order to, we would like to answer the following questions during our research: \n",
    "    * How does the RS  propose a specific recommendation?\n",
    "    * How is explainability of a prediction relevant for the context of energy-efficiency in a Smart Home? \n",
    "    * How can explainability be used for increasing acceptance of the recommendations in users?\n",
    "    * Which criteria is relevant for explainability of a Recommender System in this context?\n",
    "    * How can the performance of the RS be improved e.g. through feature engineering or model complexity?   \n",
    "    * How does the RS perform in comparison to the SOTA?\n",
    "    * How does our model perform on different data sources i.e. how generalizable is it?\n",
    "\n",
    "Additionally, we will take different user profiles into account, considering them either from an econ or eco perspective and develop our own criteria for addressing the explainability issue in the context of a smart home environment.\n",
    "\n",
    "# Expected results & contribution\n",
    "\n",
    "We hope to enhance the promising multi-agent RS by Germaine et. al (2021) through increasing the performance of the different agents. We will enhance the load agent by equipping it with a suitable approach to predict the device usage per hour of the shiftable device. The user-availability agent and the usage agent will be enhanced by applying more advanced ML models than logistic regression.\n",
    "We further expect to develop multiple methods to address explainability, while simultaneously targeting performance. We compare all methods with regards to the two criteria and therefore give a suggestion for this use case. Also, the methods will be applied to different data sources, to also include the generalizability of the chosen approaches.\n",
    "To measure the performance, we will assess the Mean-Squared-Error for the Load Agent, the AUROC for the Activity and Usage Agent, and the Recommendation Agent by its sensitivity and its ecological, as well as economical savings. We will tune the hyperparameters with grid search and/or random search. Regarding explainability, Rosenfeldt (2021) gives a recent overview and suggestions for metrics for explainability.\n",
    "The targeted results will outperform previous efforts by Germaine et al. (2021) and match competitive performance to the state-of-the-art.\n",
    "\n",
    " \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# References\n",
    "\n",
    "*   Germaine, F., Hagel, L., Riabchuk, V. (2021). Demand Response and Recommender Systems for Load Shifting. (Unpublished     Seminar Paper from Information Systems Seminar)\n",
    "\n",
    "*   Grimaldo, A. I., & Novak, J. (2019, September). User-centered visual analytics approach for interactive and               explainable energy demand analysis in prosumer scenarios. In International Conference on Computer Vision Systems (pp.     700-710). Springer, Cham.\n",
    "\n",
    "*   Himeur, Y., Alsalemi, A., Al-Kababji, A., Bensaali, F., Amira, A., Sardianos, C., ... & Varlamis, I. (2021). A survey     of recommender systems for energy efficiency in buildings: Principles, challenges and prospects. Information Fusion,      72, 1-21.\n",
    "\n",
    "*   Kolb, D. Persuasive Technology inside Smart Homes. in the Internet of Things Era, 48.\n",
    "\n",
    "*   Rosenfeld, A. (2021, May). Better Metrics for Evaluating Explainable Artificial Intelligence. In Proceedings of the       20th International Conference on Autonomous Agents and MultiAgent Systems (pp. 45-50).\n",
    "\n",
    "*   Sardianos, C., Varlamis, I., Chronis, C., Dimitrakopoulos, G., Alsalemi, A., Himeur, Y., ... & Amira, A. (2021). The      emergence of explainability of intelligent systems: Delivering explainable and personalized recommendations for           energy efficiency. International Journal of Intelligent Systems, 36(2), 656-680.\n",
    "\n",
    "*   Zhang, Y., & Chen, X. (2020). Explainable recommendation: A survey and new perspectives. Foundations and Trends in        Information Retrieval, 14(1), 1-101.\n",
    "\n",
    "*   Zhang, R., Xu, Y., Dong, Z. Y., Kong, W., & Wong, K. P. (2016, July). A composite k-nearest neighbor model for            day-ahead load forecasting with limited temperature forecasts. In 2016 IEEE Power and Energy Society General Meeting      (PESGM) (pp. 1-5). IEEE.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}