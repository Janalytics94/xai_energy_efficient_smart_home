"""20201205_Agents_LHA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KxIfN96_7dUyEypTynX-sPzZX7X0QxrD
"""

import matplotlib.pyplot as plt

# Standards
import time
import numpy as np
import pandas as pd

# current Logit Model
import statsmodels
import statsmodels.api as sm
import sklearn.metrics

import sklearn as sk 
from scripts.helper_functions import Helper


class Load_Agent:

  def __init__(self, load_input_df):
    self.input = load_input_df


  def prove_start_end_date(self, df, date):
    import pandas as pd

    start_date = (df.index[0]).strftime('%Y-%m-%d')
    end_date = date

    if len(df[start_date]) < 24:
      start_date = (pd.to_datetime(start_date) + pd.Timedelta(days = 1)).strftime('%Y-%m-%d')
      df = df[start_date:end_date]
    else: 
      df = df[:end_date]

    if len(df[end_date]) < 24:
      end_new = (pd.to_datetime(end_date) - pd.Timedelta(days = 1)).strftime('%Y-%m-%d')
      df = df[:end_new]
    else: 
      df = df[:end_date]
    return df


  def df_yesterday_date(self, df, date):
    import pandas as pd

    yesterday = (pd.to_datetime(date) - pd.Timedelta(days = 1)).strftime('%Y-%m-%d')
    return df[:yesterday]


  def load_profile_raw(self, df, shiftable_devices):
    import pandas as pd

    hours = [] 
    for hour in range(1,25):
      hours.append('h' + str(hour))
    df_hours = {}

    for idx, appliance in enumerate(shiftable_devices): # delete enumerate if we do not need integers indexes of devices
      df_hours[appliance] = pd.DataFrame(index = None, columns = hours)
      column = df[appliance]

      for i in range(len(column)):

        if (i == 0) and (column[0] > 0):
          df_hours[appliance].loc[0, 'h' + str(1)] = column[0]

        elif (column[i - 1] == 0) and (column[i] > 0):
          for j in range(0, 24): 
            if (i + j) < len(column):
              if (column[i + j] > 0):
                df_hours[appliance].loc[i, 'h' + str(j + 1)] = column[i + j]

    return df_hours


  def load_profile_cleaned(self, df_hours):

    for app in df_hours.keys():
      for i in df_hours[app].index:
        for j in df_hours[app].columns:
          if np.isnan(df_hours[app].loc[i, j]):
            df_hours[app].loc[i, j:] = 0 
    return df_hours


  def load_profile(self, df_hours, shiftable_devices): 
    import pandas as pd

    hours = df_hours[shiftable_devices[0]].columns
    loads = pd.DataFrame(columns = hours)

    for app in df_hours.keys():
      app_mean = df_hours[app].apply(lambda x: x.mean(), axis = 0)
      for hour in app_mean.index:
        loads.loc[app, hour] = app_mean[hour]

    loads = loads.fillna(0)   
    return loads


  def pipeline(self, df, date, shiftable_devices):
        # kann mann dann self benutzen?
        df = self.prove_start_end_date(df, date)
        df = self.df_yesterday_date(df, date)
        df_hours = self.load_profile_raw(df, shiftable_devices)
        df_hours = self.load_profile_cleaned(df_hours)
        loads = self.load_profile(df_hours, shiftable_devices)

        return loads

class Usage_Agent:
    def __init__(self, input_df, device):
        self.input = input_df
        self.device = device


    def train_test_split(self, df, date, train_start='2013-11-01'):
      select_vars =  [self.device + '_usage', self.device+ '_usage_lag_1', self.device+ '_usage_lag_2',	'active_last_2_days']
      df = df[select_vars]
      X_train = df.loc[train_start:date, df.columns != self.device + '_usage']
      y_train = df.loc[train_start:date, df.columns == self.device + '_usage']
      X_test  = df.loc[date, df.columns != self.device + '_usage']
      y_test  = df.loc[date , df.columns == self.device + '_usage']
      return X_train, y_train, X_test, y_test

#################### MINE ###################################################################################################
    def fit_skModels(self,model, X, y):

        return  

    def fit_smLogit(self, X, y):
      return sm.Logit(y, X).fit(disp=False)

    def fit(self, X, y, model_type):
      if model_type == 'logit':
          model = self.fit_smLogit(X, y)
      else:
        raise InputError('Unknown model type.')
      return model

    def predict(self, model, X):
      X = np.array(X)

      if type(model) == statsmodels.discrete.discrete_model.BinaryResultsWrapper:
          y_hat = model.predict(X)
      else:
          raise InputError('Unknown model type.')
      return y_hat

    def pipeline(self, df, date, model_type, train_start):
      X_train, y_train, X_test, y_test = self.train_test_split(df, date, train_start)
      model = self.fit(X_train, y_train, model_type)
      return self.predict(model, X_test)


    def auc(self, y_true, y_hat):
      import sklearn.metrics
      return sklearn.metrics.roc_auc_score(y_true, y_hat)


    def evaluate(self, df, model_type, train_start, predict_start='2014-01-01', predict_end=-1):
      dates = pd.DataFrame(df.index)
      dates = dates.set_index(df.index)['Time']
      predict_start = pd.to_datetime(predict_start)
      predict_end = pd.to_datetime(dates.iloc[predict_end]) if type(predict_end) == int else pd.to_datetime(predict_end)
      dates = dates.loc[predict_start:predict_end]
      y_true = []
      y_hat_train = {}
      y_hat_test = []
      auc_train_dict = {}
      auc_test = []

      for date in dates.index:
          # train test split
          #train_test_split(self, df, date, train_start='2013-11-01', test_delta='all', target='activity')
          X_train, y_train, X_test, y_test = self.train_test_split(df, date, train_start)

          # fit model
          model = self.fit(X_train, y_train, model_type)

          # predict
          y_hat_train.update({date: self.predict(model, X_train)})
          y_hat_test += list(self.predict(model, X_test))

          # evaluate train data
          auc_train_dict.update({date: self.auc(y_train, list(y_hat_train.values())[-1])})
        
          y_true += list(y_test)
    
      auc_test = self.auc(y_true, y_hat_test)
      auc_train = np.mean(list(auc_train_dict.values()))

      return auc_train, auc_test, auc_train_dict

